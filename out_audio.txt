(128, 207)
exp_path: model/action-model/Testexp-SGD-share_params_Y-lr_3e-3-bS_128_207/epic-5seg-disDA_none-alpha_0-advDA_RevGrad-beta_0.75_0.75_0.5-useBN_none-addlossDA_attentive_entropy-gamma_0.003-ensDA_none-mu_0-useAttn_TransAttn-n_attn_1/
Audio
Baseline: video
Frame aggregation method: trn-m
target data usage: uSv
Apply the adversarial-based Domain Adaptation approach: RevGrad
preparing the model......
Multi-Scale Temporal Relation Network Module in use ['5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']
using SGD
checking the checkpoint......
loading data......
start training......
Train: [1][0/126], lr: 0.00300	Time 1.040 (1.040)	Data 0.617 (0.617)	Prec@1 0.781 (0.781)	Prec@1 0.000 (0.000)	Prec@1 0.000 (0.000)	Prec@5 5.469 (5.469)	Prec@5 0.781 (0.781)	Prec@5 0.781 (0.781)	Loss 7.2462 (7.2462)   loss_verb 4.5745   loss_noun 5.7044	beta 0.012, 0.012, 0.008  loss_a 2.0807	gamma 0.003000  loss_e_verb 7.7455 loss_e_noun 9.6572	
Train: [1][50/126], lr: 0.00300	Time 0.088 (0.108)	Data 0.022 (0.029)	Prec@1 41.406 (25.475)	Prec@1 13.281 (7.613)	Prec@1 9.375 (2.803)	Prec@5 71.094 (63.634)	Prec@5 33.594 (21.492)	Prec@5 31.250 (16.575)	Loss 5.2326 (5.9331)   loss_verb 3.0105   loss_noun 4.7318	beta 0.017, 0.017, 0.012  loss_a 2.0421	gamma 0.003000  loss_e_verb 5.0329 loss_e_noun 8.1309	
Train: [1][100/126], lr: 0.00300	Time 0.094 (0.098)	Data 0.026 (0.024)	Prec@1 40.625 (33.362)	Prec@1 12.500 (10.651)	Prec@1 8.594 (5.701)	Prec@5 76.562 (68.820)	Prec@5 35.156 (26.346)	Prec@5 29.688 (22.068)	Loss 5.1125 (5.5785)   loss_verb 2.6321   loss_noun 4.4502	beta 0.022, 0.022, 0.015  loss_a 2.0193	gamma 0.003000  loss_e_verb 4.4377 loss_e_noun 7.6180	
Train: [2][0/126], lr: 0.00300	Time 0.720 (0.720)	Data 0.671 (0.671)	Prec@1 44.531 (44.531)	Prec@1 17.188 (17.188)	Prec@1 10.156 (10.156)	Prec@5 73.438 (73.438)	Prec@5 36.719 (36.719)	Prec@5 30.469 (30.469)	Loss 5.0333 (5.0333)   loss_verb 2.1647   loss_noun 3.9417	beta 0.025, 0.025, 0.017  loss_a 1.9640	gamma 0.003000  loss_e_verb 3.7592 loss_e_noun 7.0264	
Train: [2][50/126], lr: 0.00300	Time 0.097 (0.111)	Data 0.017 (0.032)	Prec@1 39.844 (44.746)	Prec@1 21.875 (18.306)	Prec@1 14.062 (12.132)	Prec@5 75.781 (77.788)	Prec@5 39.844 (40.196)	Prec@5 35.938 (35.769)	Loss 4.9587 (4.9448)   loss_verb 2.0983   loss_noun 3.8276	beta 0.030, 0.030, 0.020  loss_a 1.9667	gamma 0.003000  loss_e_verb 3.5162 loss_e_noun 6.5964	
Train: [2][100/126], lr: 0.00300	Time 0.095 (0.100)	Data 0.022 (0.026)	Prec@1 49.219 (45.189)	Prec@1 15.625 (18.998)	Prec@1 9.375 (12.546)	Prec@5 79.688 (77.893)	Prec@5 42.969 (41.089)	Prec@5 39.062 (36.278)	Loss 4.8140 (4.9099)   loss_verb 2.0857   loss_noun 3.7949	beta 0.035, 0.035, 0.023  loss_a 1.9546	gamma 0.003000  loss_e_verb 3.4821 loss_e_noun 6.5175	
Train: [3][0/126], lr: 0.00300	Time 0.713 (0.713)	Data 0.671 (0.671)	Prec@1 50.000 (50.000)	Prec@1 26.562 (26.562)	Prec@1 19.531 (19.531)	Prec@5 77.344 (77.344)	Prec@5 46.094 (46.094)	Prec@5 42.969 (42.969)	Loss 4.7495 (4.7495)   loss_verb 2.0412   loss_noun 3.5495	beta 0.037, 0.037, 0.025  loss_a 1.9396	gamma 0.003000  loss_e_verb 3.3448 loss_e_noun 6.3421	
Train: [3][50/126], lr: 0.00300	Time 0.089 (0.111)	Data 0.021 (0.034)	Prec@1 50.000 (47.289)	Prec@1 24.219 (22.304)	Prec@1 18.750 (14.752)	Prec@5 77.344 (79.580)	Prec@5 53.125 (46.216)	Prec@5 47.656 (41.222)	Loss 4.6227 (4.7089)   loss_verb 1.9602   loss_noun 3.5462	beta 0.042, 0.042, 0.028  loss_a 1.9415	gamma 0.003000  loss_e_verb 3.3001 loss_e_noun 6.1628	
Train: [3][100/126], lr: 0.00300	Time 0.086 (0.101)	Data 0.021 (0.027)	Prec@1 46.875 (47.548)	Prec@1 21.094 (22.718)	Prec@1 15.625 (14.952)	Prec@5 82.031 (79.804)	Prec@5 53.125 (46.434)	Prec@5 49.219 (41.329)	Loss 4.5883 (4.6867)   loss_verb 1.9475   loss_noun 3.5320	beta 0.047, 0.047, 0.032  loss_a 1.9328	gamma 0.003000  loss_e_verb 3.2821 loss_e_noun 6.1395	
Train: [4][0/126], lr: 0.00300	Time 0.712 (0.712)	Data 0.666 (0.666)	Prec@1 57.812 (57.812)	Prec@1 25.000 (25.000)	Prec@1 16.406 (16.406)	Prec@5 84.375 (84.375)	Prec@5 53.125 (53.125)	Prec@5 45.312 (45.312)	Loss 4.4148 (4.4148)   loss_verb 1.6638   loss_noun 3.3294	beta 0.050, 0.050, 0.033  loss_a 1.9040	gamma 0.003000  loss_e_verb 3.2377 loss_e_noun 6.2191	
Train: [4][50/126], lr: 0.00300	Time 0.090 (0.110)	Data 0.017 (0.035)	Prec@1 54.688 (50.092)	Prec@1 32.812 (24.831)	Prec@1 24.219 (16.759)	Prec@5 82.031 (81.863)	Prec@5 54.688 (50.383)	Prec@5 49.219 (45.037)	Loss 4.2193 (4.5069)   loss_verb 1.8358   loss_noun 3.3322	beta 0.055, 0.055, 0.037  loss_a 1.9093	gamma 0.003000  loss_e_verb 3.1387 loss_e_noun 5.9464	
Train: [4][100/126], lr: 0.00300	Time 0.086 (0.100)	Data 0.020 (0.028)	Prec@1 46.875 (50.008)	Prec@1 21.875 (24.992)	Prec@1 14.062 (17.017)	Prec@5 77.344 (81.691)	Prec@5 43.750 (50.480)	Prec@5 37.500 (45.088)	Loss 4.7526 (4.5240)   loss_verb 1.8453   loss_noun 3.3474	beta 0.060, 0.060, 0.040  loss_a 1.9140	gamma 0.003000  loss_e_verb 3.1435 loss_e_noun 5.9433	
Train: [5][0/126], lr: 0.00300	Time 0.713 (0.713)	Data 0.668 (0.668)	Prec@1 46.094 (46.094)	Prec@1 30.469 (30.469)	Prec@1 19.531 (19.531)	Prec@5 84.375 (84.375)	Prec@5 60.938 (60.938)	Prec@5 54.688 (54.688)	Loss 4.3056 (4.3056)   loss_verb 1.7324   loss_noun 2.9508	beta 0.062, 0.062, 0.042  loss_a 1.9507	gamma 0.003000  loss_e_verb 3.2334 loss_e_noun 5.6722	
Train: [5][50/126], lr: 0.00300	Time 0.097 (0.109)	Data 0.021 (0.034)	Prec@1 53.125 (50.812)	Prec@1 35.156 (27.221)	Prec@1 23.438 (18.107)	Prec@5 85.156 (82.858)	Prec@5 62.500 (53.248)	Prec@5 57.031 (48.009)	Loss 4.1926 (4.4602)   loss_verb 1.7889   loss_noun 3.2290	beta 0.067, 0.067, 0.045  loss_a 1.9379	gamma 0.003000  loss_e_verb 3.1026 loss_e_noun 5.7860	
Train: [5][100/126], lr: 0.00300	Time 0.085 (0.099)	Data 0.020 (0.027)	Prec@1 55.469 (51.253)	Prec@1 28.906 (26.980)	Prec@1 20.312 (18.131)	Prec@5 80.469 (83.075)	Prec@5 51.562 (53.024)	Prec@5 44.531 (47.749)	Loss 4.3641 (4.4514)   loss_verb 1.7738   loss_noun 3.2217	beta 0.072, 0.072, 0.048  loss_a 1.9404	gamma 0.003000  loss_e_verb 3.0708 loss_e_noun 5.7361	
Train: [6][0/126], lr: 0.00300	Time 0.709 (0.709)	Data 0.662 (0.662)	Prec@1 50.000 (50.000)	Prec@1 23.438 (23.438)	Prec@1 17.188 (17.188)	Prec@5 83.594 (83.594)	Prec@5 58.594 (58.594)	Prec@5 51.562 (51.562)	Loss 4.4573 (4.4573)   loss_verb 1.8174   loss_noun 3.2242	beta 0.075, 0.075, 0.050  loss_a 1.9237	gamma 0.003000  loss_e_verb 2.8670 loss_e_noun 5.6410	
Train: [6][50/126], lr: 0.00300	Time 0.084 (0.107)	Data 0.026 (0.036)	Prec@1 54.688 (53.232)	Prec@1 25.781 (28.477)	Prec@1 20.312 (19.761)	Prec@5 88.281 (84.252)	Prec@5 60.938 (56.556)	Prec@5 58.594 (51.164)	Loss 4.2685 (4.3476)   loss_verb 1.6972   loss_noun 3.0907	beta 0.080, 0.080, 0.053  loss_a 1.9410	gamma 0.003000  loss_e_verb 2.8525 loss_e_noun 5.5106	
Train: [6][100/126], lr: 0.00300	Time 0.095 (0.099)	Data 0.020 (0.029)	Prec@1 53.906 (53.187)	Prec@1 25.000 (28.929)	Prec@1 17.188 (20.289)	Prec@5 83.594 (84.058)	Prec@5 53.906 (56.590)	Prec@5 50.000 (51.346)	Loss 4.3221 (4.3442)   loss_verb 1.7018   loss_noun 3.0813	beta 0.085, 0.085, 0.056  loss_a 1.9401	gamma 0.003000  loss_e_verb 2.8672 loss_e_noun 5.4768	
Train: [7][0/126], lr: 0.00300	Time 0.707 (0.707)	Data 0.662 (0.662)	Prec@1 52.344 (52.344)	Prec@1 25.000 (25.000)	Prec@1 14.062 (14.062)	Prec@5 89.062 (89.062)	Prec@5 58.594 (58.594)	Prec@5 56.250 (56.250)	Loss 4.2448 (4.2448)   loss_verb 1.5491   loss_noun 2.9962	beta 0.087, 0.087, 0.058  loss_a 1.9592	gamma 0.003000  loss_e_verb 3.0420 loss_e_noun 5.5508	
Train: [7][50/126], lr: 0.00300	Time 0.080 (0.109)	Data 0.016 (0.036)	Prec@1 60.156 (53.891)	Prec@1 28.125 (30.162)	Prec@1 25.781 (21.140)	Prec@5 85.938 (84.727)	Prec@5 60.156 (57.828)	Prec@5 57.812 (52.574)	Loss 4.1013 (4.2646)   loss_verb 1.6440   loss_noun 2.9995	beta 0.092, 0.092, 0.061  loss_a 1.9305	gamma 0.003000  loss_e_verb 2.8388 loss_e_noun 5.3940	
Train: [7][100/126], lr: 0.00300	Time 0.083 (0.099)	Data 0.017 (0.029)	Prec@1 55.469 (53.682)	Prec@1 30.469 (30.206)	Prec@1 21.094 (21.163)	Prec@5 90.625 (84.723)	Prec@5 57.812 (57.635)	Prec@5 54.688 (52.382)	Loss 4.2297 (4.2744)   loss_verb 1.6567   loss_noun 3.0035	beta 0.097, 0.097, 0.065  loss_a 1.9321	gamma 0.003000  loss_e_verb 2.7819 loss_e_noun 5.3247	
Train: [8][0/126], lr: 0.00300	Time 0.712 (0.712)	Data 0.666 (0.666)	Prec@1 40.625 (40.625)	Prec@1 28.125 (28.125)	Prec@1 14.844 (14.844)	Prec@5 81.250 (81.250)	Prec@5 57.031 (57.031)	Prec@5 49.219 (49.219)	Loss 4.5447 (4.5447)   loss_verb 1.9357   loss_noun 3.2290	beta 0.099, 0.099, 0.066  loss_a 1.9490	gamma 0.003000  loss_e_verb 3.1931 loss_e_noun 5.7153	
Train: [8][50/126], lr: 0.00300	Time 0.091 (0.111)	Data 0.024 (0.033)	Prec@1 52.344 (55.699)	Prec@1 34.375 (31.893)	Prec@1 25.000 (22.687)	Prec@5 86.719 (85.478)	Prec@5 57.812 (59.865)	Prec@5 53.906 (54.519)	Loss 4.2231 (4.1857)   loss_verb 1.5872   loss_noun 2.8991	beta 0.104, 0.104, 0.070  loss_a 1.9308	gamma 0.003000  loss_e_verb 2.6748 loss_e_noun 5.1144	
Train: [8][100/126], lr: 0.00300	Time 0.098 (0.101)	Data 0.023 (0.028)	Prec@1 53.125 (54.904)	Prec@1 32.812 (31.536)	Prec@1 20.312 (22.239)	Prec@5 89.062 (85.272)	Prec@5 60.156 (59.476)	Prec@5 54.688 (54.223)	Loss 4.2379 (4.2090)   loss_verb 1.6159   loss_noun 2.9204	beta 0.109, 0.109, 0.073  loss_a 1.9292	gamma 0.003000  loss_e_verb 2.6823 loss_e_noun 5.1169	
Train: [9][0/126], lr: 0.00300	Time 0.704 (0.704)	Data 0.669 (0.669)	Prec@1 51.562 (51.562)	Prec@1 28.906 (28.906)	Prec@1 15.625 (15.625)	Prec@5 88.281 (88.281)	Prec@5 57.031 (57.031)	Prec@5 50.781 (50.781)	Loss 4.2279 (4.2279)   loss_verb 1.5964   loss_noun 3.0374	beta 0.112, 0.112, 0.074  loss_a 1.8991	gamma 0.003000  loss_e_verb 2.7410 loss_e_noun 5.2143	
Train: [9][50/126], lr: 0.00300	Time 0.081 (0.108)	Data 0.017 (0.035)	Prec@1 53.906 (54.979)	Prec@1 35.156 (33.272)	Prec@1 25.781 (23.070)	Prec@5 85.156 (85.692)	Prec@5 57.812 (60.968)	Prec@5 52.344 (55.790)	Loss 4.1494 (4.1274)   loss_verb 1.5692   loss_noun 2.8417	beta 0.117, 0.117, 0.078  loss_a 1.9105	gamma 0.003000  loss_e_verb 2.6086 loss_e_noun 4.9989	
Train: [9][100/126], lr: 0.00300	Time 0.085 (0.099)	Data 0.017 (0.028)	Prec@1 60.938 (55.337)	Prec@1 31.250 (33.037)	Prec@1 25.781 (23.391)	Prec@5 88.281 (85.729)	Prec@5 60.156 (60.736)	Prec@5 57.031 (55.709)	Loss 4.1781 (4.1276)   loss_verb 1.5732   loss_noun 2.8448	beta 0.121, 0.121, 0.081  loss_a 1.9072	gamma 0.003000  loss_e_verb 2.6074 loss_e_noun 4.9922	
Train: [10][0/126], lr: 0.00030	Time 0.735 (0.735)	Data 0.686 (0.686)	Prec@1 59.375 (59.375)	Prec@1 42.188 (42.188)	Prec@1 32.031 (32.031)	Prec@5 89.844 (89.844)	Prec@5 67.188 (67.188)	Prec@5 64.062 (64.062)	Loss 3.8690 (3.8690)   loss_verb 1.3060   loss_noun 2.5431	beta 0.124, 0.124, 0.083  loss_a 1.9337	gamma 0.003000  loss_e_verb 2.4164 loss_e_noun 4.7372	
Train: [10][50/126], lr: 0.00030	Time 0.085 (0.109)	Data 0.019 (0.034)	Prec@1 54.688 (57.384)	Prec@1 33.594 (34.513)	Prec@1 27.344 (24.908)	Prec@5 83.594 (86.887)	Prec@5 66.406 (64.154)	Prec@5 57.812 (58.686)	Loss 4.1415 (4.0085)   loss_verb 1.4806   loss_noun 2.7095	beta 0.129, 0.129, 0.086  loss_a 1.9023	gamma 0.003000  loss_e_verb 2.5428 loss_e_noun 4.9016	
Train: [10][100/126], lr: 0.00030	Time 0.090 (0.099)	Data 0.022 (0.028)	Prec@1 60.156 (57.433)	Prec@1 35.938 (35.690)	Prec@1 25.781 (25.712)	Prec@5 88.281 (87.129)	Prec@5 60.938 (64.032)	Prec@5 57.031 (59.004)	Loss 3.9974 (3.9920)   loss_verb 1.4709   loss_noun 2.6867	beta 0.133, 0.133, 0.089  loss_a 1.9020	gamma 0.003000  loss_e_verb 2.5378 loss_e_noun 4.8738	
Train: [11][0/126], lr: 0.00030	Time 0.721 (0.721)	Data 0.672 (0.672)	Prec@1 65.625 (65.625)	Prec@1 40.625 (40.625)	Prec@1 28.906 (28.906)	Prec@5 86.719 (86.719)	Prec@5 71.875 (71.875)	Prec@5 64.844 (64.844)	Loss 3.7658 (3.7658)   loss_verb 1.4005   loss_noun 2.3339	beta 0.136, 0.136, 0.091  loss_a 1.8877	gamma 0.003000  loss_e_verb 2.4833 loss_e_noun 4.7848	
Train: [11][50/126], lr: 0.00030	Time 0.099 (0.108)	Data 0.027 (0.036)	Prec@1 63.281 (58.747)	Prec@1 42.188 (36.351)	Prec@1 32.812 (26.287)	Prec@5 89.844 (87.270)	Prec@5 71.094 (65.732)	Prec@5 64.844 (60.401)	Loss 3.7260 (3.9457)   loss_verb 1.4483   loss_noun 2.6312	beta 0.141, 0.141, 0.094  loss_a 1.8950	gamma 0.003000  loss_e_verb 2.4871 loss_e_noun 4.8000	
Train: [11][100/126], lr: 0.00030	Time 0.087 (0.099)	Data 0.022 (0.028)	Prec@1 56.250 (58.787)	Prec@1 43.750 (36.688)	Prec@1 30.469 (26.787)	Prec@5 85.938 (87.539)	Prec@5 65.625 (65.633)	Prec@5 58.594 (60.729)	Loss 3.8131 (3.9353)   loss_verb 1.4341   loss_noun 2.6237	beta 0.146, 0.146, 0.097  loss_a 1.8955	gamma 0.003000  loss_e_verb 2.4812 loss_e_noun 4.7775	
Train: [12][0/126], lr: 0.00030	Time 0.752 (0.752)	Data 0.694 (0.694)	Prec@1 50.781 (50.781)	Prec@1 39.844 (39.844)	Prec@1 28.906 (28.906)	Prec@5 89.062 (89.062)	Prec@5 65.625 (65.625)	Prec@5 64.062 (64.062)	Loss 3.9621 (3.9621)   loss_verb 1.5461   loss_noun 2.5660	beta 0.148, 0.148, 0.099  loss_a 1.8951	gamma 0.003000  loss_e_verb 2.5556 loss_e_noun 4.7744	
Train: [12][50/126], lr: 0.00030	Time 0.092 (0.109)	Data 0.018 (0.035)	Prec@1 54.688 (59.053)	Prec@1 39.062 (37.944)	Prec@1 24.219 (27.436)	Prec@5 89.844 (87.515)	Prec@5 67.969 (66.039)	Prec@5 63.281 (61.014)	Loss 3.9132 (3.9103)   loss_verb 1.4402   loss_noun 2.5739	beta 0.153, 0.153, 0.102  loss_a 1.8924	gamma 0.003000  loss_e_verb 2.4843 loss_e_noun 4.7657	
Train: [12][100/126], lr: 0.00030	Time 0.097 (0.100)	Data 0.023 (0.028)	Prec@1 50.781 (58.648)	Prec@1 37.500 (37.345)	Prec@1 25.000 (26.795)	Prec@5 82.031 (87.407)	Prec@5 63.281 (65.563)	Prec@5 54.688 (60.528)	Loss 4.2146 (3.9244)   loss_verb 1.4429   loss_noun 2.5997	beta 0.158, 0.158, 0.105  loss_a 1.8923	gamma 0.003000  loss_e_verb 2.4775 loss_e_noun 4.7566	
Train: [13][0/126], lr: 0.00030	Time 0.709 (0.709)	Data 0.665 (0.665)	Prec@1 57.031 (57.031)	Prec@1 35.156 (35.156)	Prec@1 26.562 (26.562)	Prec@5 88.281 (88.281)	Prec@5 63.281 (63.281)	Prec@5 58.594 (58.594)	Loss 3.9894 (3.9894)   loss_verb 1.4575   loss_noun 2.6976	beta 0.160, 0.160, 0.107  loss_a 1.9013	gamma 0.003000  loss_e_verb 2.3480 loss_e_noun 4.6930	
Train: [13][50/126], lr: 0.00030	Time 0.093 (0.108)	Data 0.023 (0.036)	Prec@1 54.688 (58.594)	Prec@1 35.156 (37.286)	Prec@1 25.000 (27.145)	Prec@5 89.844 (88.281)	Prec@5 57.812 (66.268)	Prec@5 55.469 (61.412)	Loss 4.1248 (3.9113)   loss_verb 1.4219   loss_noun 2.5891	beta 0.165, 0.165, 0.110  loss_a 1.8951	gamma 0.003000  loss_e_verb 2.4257 loss_e_noun 4.6972	
Train: [13][100/126], lr: 0.00030	Time 0.093 (0.099)	Data 0.019 (0.028)	Prec@1 56.250 (59.058)	Prec@1 33.594 (37.724)	Prec@1 25.000 (27.529)	Prec@5 90.625 (88.219)	Prec@5 64.062 (66.112)	Prec@5 60.938 (61.363)	Loss 3.9955 (3.9059)   loss_verb 1.4121   loss_noun 2.5874	beta 0.169, 0.169, 0.113  loss_a 1.8954	gamma 0.003000  loss_e_verb 2.4269 loss_e_noun 4.7074	
Train: [14][0/126], lr: 0.00030	Time 0.704 (0.704)	Data 0.663 (0.663)	Prec@1 60.938 (60.938)	Prec@1 39.062 (39.062)	Prec@1 27.344 (27.344)	Prec@5 86.719 (86.719)	Prec@5 69.531 (69.531)	Prec@5 64.844 (64.844)	Loss 3.9099 (3.9099)   loss_verb 1.4645   loss_noun 2.5262	beta 0.172, 0.172, 0.115  loss_a 1.9038	gamma 0.003000  loss_e_verb 2.5013 loss_e_noun 4.6793	
Train: [14][50/126], lr: 0.00030	Time 0.095 (0.111)	Data 0.016 (0.033)	Prec@1 67.188 (59.084)	Prec@1 39.062 (38.986)	Prec@1 33.594 (28.248)	Prec@5 89.844 (88.465)	Prec@5 63.281 (66.973)	Prec@5 61.719 (62.607)	Loss 3.7799 (3.8733)   loss_verb 1.3929   loss_noun 2.5346	beta 0.177, 0.177, 0.118  loss_a 1.8989	gamma 0.003000  loss_e_verb 2.4338 loss_e_noun 4.6872	
Train: [14][100/126], lr: 0.00030	Time 0.089 (0.101)	Data 0.016 (0.027)	Prec@1 65.625 (59.561)	Prec@1 34.375 (38.065)	Prec@1 29.688 (27.901)	Prec@5 89.062 (88.506)	Prec@5 64.062 (66.607)	Prec@5 60.156 (62.098)	Loss 3.8349 (3.8835)   loss_verb 1.3906   loss_noun 2.5619	beta 0.181, 0.181, 0.121  loss_a 1.8966	gamma 0.003000  loss_e_verb 2.4200 loss_e_noun 4.6726	
Train: [15][0/126], lr: 0.00030	Time 0.749 (0.749)	Data 0.693 (0.693)	Prec@1 64.844 (64.844)	Prec@1 40.625 (40.625)	Prec@1 30.469 (30.469)	Prec@5 91.406 (91.406)	Prec@5 64.062 (64.062)	Prec@5 60.938 (60.938)	Loss 3.7623 (3.7623)   loss_verb 1.1989   loss_noun 2.5192	beta 0.184, 0.184, 0.122  loss_a 1.8927	gamma 0.003000  loss_e_verb 2.4574 loss_e_noun 4.6071	
Train: [15][50/126], lr: 0.00030	Time 0.096 (0.111)	Data 0.015 (0.031)	Prec@1 60.938 (60.187)	Prec@1 39.062 (38.511)	Prec@1 28.125 (27.834)	Prec@5 89.062 (88.603)	Prec@5 65.625 (67.142)	Prec@5 63.281 (62.469)	Loss 3.8114 (3.8661)   loss_verb 1.3711   loss_noun 2.5434	beta 0.188, 0.188, 0.126  loss_a 1.8984	gamma 0.003000  loss_e_verb 2.3806 loss_e_noun 4.6165	
Train: [15][100/126], lr: 0.00030	Time 0.100 (0.101)	Data 0.020 (0.025)	Prec@1 58.594 (59.793)	Prec@1 40.625 (38.103)	Prec@1 26.562 (27.847)	Prec@5 90.625 (88.521)	Prec@5 68.750 (66.785)	Prec@5 64.062 (62.183)	Loss 3.8711 (3.8786)   loss_verb 1.3840   loss_noun 2.5555	beta 0.193, 0.193, 0.129  loss_a 1.8984	gamma 0.003000  loss_e_verb 2.3854 loss_e_noun 4.6322	
Train: [16][0/126], lr: 0.00030	Time 0.744 (0.744)	Data 0.698 (0.698)	Prec@1 62.500 (62.500)	Prec@1 46.875 (46.875)	Prec@1 35.156 (35.156)	Prec@5 95.312 (95.312)	Prec@5 71.094 (71.094)	Prec@5 67.969 (67.969)	Loss 3.6629 (3.6629)   loss_verb 1.2229   loss_noun 2.2871	beta 0.195, 0.195, 0.130  loss_a 1.8974	gamma 0.003000  loss_e_verb 2.4540 loss_e_noun 4.5292	
Train: [16][50/126], lr: 0.00030	Time 0.092 (0.112)	Data 0.016 (0.034)	Prec@1 60.156 (60.355)	Prec@1 43.750 (38.955)	Prec@1 30.469 (28.768)	Prec@5 86.719 (88.710)	Prec@5 71.094 (67.004)	Prec@5 64.844 (62.286)	Loss 3.8120 (3.8449)   loss_verb 1.3632   loss_noun 2.5058	beta 0.200, 0.200, 0.133  loss_a 1.8999	gamma 0.003000  loss_e_verb 2.4102 loss_e_noun 4.6183	
Train: [16][100/126], lr: 0.00030	Time 0.085 (0.101)	Data 0.018 (0.028)	Prec@1 50.781 (60.017)	Prec@1 39.062 (38.598)	Prec@1 25.000 (28.311)	Prec@5 88.281 (88.343)	Prec@5 66.406 (67.141)	Prec@5 60.938 (62.245)	Loss 4.0140 (3.8642)   loss_verb 1.3805   loss_noun 2.5216	beta 0.205, 0.205, 0.136  loss_a 1.9027	gamma 0.003000  loss_e_verb 2.4033 loss_e_noun 4.6030	
Train: [17][0/126], lr: 0.00030	Time 0.748 (0.748)	Data 0.701 (0.701)	Prec@1 60.938 (60.938)	Prec@1 39.844 (39.844)	Prec@1 31.250 (31.250)	Prec@5 87.500 (87.500)	Prec@5 72.656 (72.656)	Prec@5 65.625 (65.625)	Loss 3.7596 (3.7596)   loss_verb 1.3707   loss_noun 2.3590	beta 0.207, 0.207, 0.138  loss_a 1.8845	gamma 0.003000  loss_e_verb 2.2478 loss_e_noun 4.6253	
Train: [17][50/126], lr: 0.00030	Time 0.088 (0.109)	Data 0.027 (0.036)	Prec@1 69.531 (59.498)	Prec@1 35.156 (40.502)	Prec@1 29.688 (29.151)	Prec@5 89.062 (88.006)	Prec@5 67.188 (68.597)	Prec@5 62.500 (63.480)	Loss 3.7651 (3.8451)   loss_verb 1.3867   loss_noun 2.4720	beta 0.212, 0.212, 0.141  loss_a 1.9053	gamma 0.003000  loss_e_verb 2.3870 loss_e_noun 4.5878	
Train: [17][100/126], lr: 0.00030	Time 0.089 (0.099)	Data 0.021 (0.029)	Prec@1 52.344 (59.878)	Prec@1 32.812 (39.650)	Prec@1 23.438 (29.123)	Prec@5 84.375 (88.382)	Prec@5 64.844 (68.209)	Prec@5 57.812 (63.266)	Loss 4.0016 (3.8507)   loss_verb 1.3724   loss_noun 2.4949	beta 0.216, 0.216, 0.144  loss_a 1.9066	gamma 0.003000  loss_e_verb 2.3803 loss_e_noun 4.5912	
Train: [18][0/126], lr: 0.00030	Time 0.731 (0.731)	Data 0.689 (0.689)	Prec@1 66.406 (66.406)	Prec@1 35.156 (35.156)	Prec@1 31.250 (31.250)	Prec@5 91.406 (91.406)	Prec@5 63.281 (63.281)	Prec@5 58.594 (58.594)	Loss 3.8110 (3.8110)   loss_verb 1.1717   loss_noun 2.5410	beta 0.218, 0.218, 0.146  loss_a 1.9445	gamma 0.003000  loss_e_verb 2.3329 loss_e_noun 4.4234	
Train: [18][50/126], lr: 0.00030	Time 0.098 (0.108)	Data 0.023 (0.036)	Prec@1 55.469 (60.738)	Prec@1 43.750 (39.461)	Prec@1 27.344 (29.167)	Prec@5 94.531 (88.618)	Prec@5 64.062 (67.555)	Prec@5 61.719 (62.653)	Loss 3.8903 (3.8513)   loss_verb 1.3664   loss_noun 2.4990	beta 0.223, 0.223, 0.149  loss_a 1.9081	gamma 0.003000  loss_e_verb 2.3863 loss_e_noun 4.5781	
Train: [18][100/126], lr: 0.00030	Time 0.095 (0.099)	Data 0.016 (0.028)	Prec@1 60.156 (60.876)	Prec@1 44.531 (39.403)	Prec@1 33.594 (29.185)	Prec@5 85.156 (88.622)	Prec@5 82.031 (67.961)	Prec@5 71.875 (63.150)	Loss 3.6753 (3.8459)   loss_verb 1.3628   loss_noun 2.4918	beta 0.228, 0.228, 0.152  loss_a 1.9083	gamma 0.003000  loss_e_verb 2.3694 loss_e_noun 4.5676	
Train: [19][0/126], lr: 0.00030	Time 0.708 (0.708)	Data 0.671 (0.671)	Prec@1 60.938 (60.938)	Prec@1 44.531 (44.531)	Prec@1 29.688 (29.688)	Prec@5 92.969 (92.969)	Prec@5 70.312 (70.312)	Prec@5 66.406 (66.406)	Loss 3.7007 (3.7007)   loss_verb 1.1918   loss_noun 2.3816	beta 0.230, 0.230, 0.153  loss_a 1.9041	gamma 0.003000  loss_e_verb 2.1619 loss_e_noun 4.4063	
Train: [19][50/126], lr: 0.00030	Time 0.100 (0.107)	Data 0.025 (0.035)	Prec@1 65.625 (60.294)	Prec@1 32.812 (39.108)	Prec@1 23.438 (28.401)	Prec@5 90.625 (88.373)	Prec@5 67.969 (67.877)	Prec@5 62.500 (62.607)	Loss 3.8599 (3.8516)   loss_verb 1.3658   loss_noun 2.4981	beta 0.234, 0.234, 0.156  loss_a 1.9093	gamma 0.003000  loss_e_verb 2.3483 loss_e_noun 4.5656	
Train: [19][100/126], lr: 0.00030	Time 0.092 (0.099)	Data 0.017 (0.028)	Prec@1 57.031 (60.791)	Prec@1 39.844 (39.256)	Prec@1 27.344 (28.752)	Prec@5 84.375 (88.428)	Prec@5 69.531 (68.193)	Prec@5 63.281 (63.150)	Loss 3.8964 (3.8432)   loss_verb 1.3596   loss_noun 2.4859	beta 0.239, 0.239, 0.159  loss_a 1.9102	gamma 0.003000  loss_e_verb 2.3231 loss_e_noun 4.5413	
Train: [20][0/126], lr: 0.00003	Time 0.721 (0.721)	Data 0.673 (0.673)	Prec@1 60.156 (60.156)	Prec@1 39.844 (39.844)	Prec@1 25.000 (25.000)	Prec@5 89.062 (89.062)	Prec@5 68.750 (68.750)	Prec@5 64.062 (64.062)	Loss 3.8232 (3.8232)   loss_verb 1.3130   loss_noun 2.5082	beta 0.241, 0.241, 0.161  loss_a 1.9025	gamma 0.003000  loss_e_verb 2.2039 loss_e_noun 4.5157	
Train: [20][50/126], lr: 0.00003	Time 0.089 (0.107)	Data 0.025 (0.035)	Prec@1 50.781 (60.692)	Prec@1 38.281 (40.150)	Prec@1 25.000 (29.534)	Prec@5 87.500 (89.047)	Prec@5 67.188 (68.336)	Prec@5 60.156 (63.634)	Loss 4.0094 (3.8275)   loss_verb 1.3371   loss_noun 2.4693	beta 0.246, 0.246, 0.164  loss_a 1.9139	gamma 0.003000  loss_e_verb 2.3675 loss_e_noun 4.5679	
Train: [20][100/126], lr: 0.00003	Time 0.089 (0.099)	Data 0.020 (0.028)	Prec@1 64.062 (60.938)	Prec@1 46.875 (40.215)	Prec@1 34.375 (29.788)	Prec@5 85.156 (88.846)	Prec@5 74.219 (68.533)	Prec@5 64.844 (63.815)	Loss 3.5948 (3.8196)   loss_verb 1.3365   loss_noun 2.4588	beta 0.250, 0.250, 0.167  loss_a 1.9115	gamma 0.003000  loss_e_verb 2.3639 loss_e_noun 4.5797	
Train: [21][0/126], lr: 0.00003	Time 0.748 (0.748)	Data 0.698 (0.698)	Prec@1 51.562 (51.562)	Prec@1 28.125 (28.125)	Prec@1 17.188 (17.188)	Prec@5 84.375 (84.375)	Prec@5 64.062 (64.062)	Prec@5 57.031 (57.031)	Loss 4.1144 (4.1144)   loss_verb 1.5265   loss_noun 2.7846	beta 0.252, 0.252, 0.168  loss_a 1.9485	gamma 0.003000  loss_e_verb 2.3535 loss_e_noun 4.4872	
Train: [21][50/126], lr: 0.00003	Time 0.088 (0.108)	Data 0.024 (0.036)	Prec@1 60.156 (61.749)	Prec@1 43.750 (39.691)	Prec@1 30.469 (29.427)	Prec@5 88.281 (89.032)	Prec@5 67.188 (68.398)	Prec@5 62.500 (63.664)	Loss 3.8355 (3.8366)   loss_verb 1.3281   loss_noun 2.4919	beta 0.257, 0.257, 0.171  loss_a 1.9163	gamma 0.003000  loss_e_verb 2.3520 loss_e_noun 4.5591	
Train: [21][100/126], lr: 0.00003	Time 0.087 (0.099)	Data 0.023 (0.029)	Prec@1 59.375 (61.108)	Prec@1 37.500 (39.851)	Prec@1 25.000 (29.479)	Prec@5 92.188 (88.722)	Prec@5 67.969 (68.827)	Prec@5 65.625 (64.078)	Loss 3.9327 (3.8266)   loss_verb 1.3392   loss_noun 2.4651	beta 0.261, 0.261, 0.174  loss_a 1.9141	gamma 0.003000  loss_e_verb 2.3476 loss_e_noun 4.5624	
Train: [22][0/126], lr: 0.00003	Time 0.706 (0.706)	Data 0.670 (0.670)	Prec@1 55.469 (55.469)	Prec@1 44.531 (44.531)	Prec@1 27.344 (27.344)	Prec@5 85.156 (85.156)	Prec@5 72.656 (72.656)	Prec@5 62.500 (62.500)	Loss 3.9429 (3.9429)   loss_verb 1.5597   loss_noun 2.4457	beta 0.263, 0.263, 0.176  loss_a 1.9300	gamma 0.003000  loss_e_verb 2.3690 loss_e_noun 4.4665	
Train: [22][50/126], lr: 0.00003	Time 0.092 (0.107)	Data 0.024 (0.035)	Prec@1 60.156 (60.754)	Prec@1 39.062 (40.242)	Prec@1 32.031 (29.703)	Prec@5 92.969 (88.588)	Prec@5 64.844 (68.122)	Prec@5 62.500 (63.465)	Loss 3.8528 (3.8351)   loss_verb 1.3472   loss_noun 2.4710	beta 0.268, 0.268, 0.178  loss_a 1.9158	gamma 0.003000  loss_e_verb 2.3364 loss_e_noun 4.5251	
Train: [22][100/126], lr: 0.00003	Time 0.089 (0.098)	Data 0.021 (0.028)	Prec@1 55.469 (60.945)	Prec@1 35.938 (39.720)	Prec@1 25.781 (29.339)	Prec@5 84.375 (88.506)	Prec@5 61.719 (67.868)	Prec@5 55.469 (63.088)	Loss 4.0162 (3.8402)   loss_verb 1.3467   loss_noun 2.4836	beta 0.272, 0.272, 0.181  loss_a 1.9148	gamma 0.003000  loss_e_verb 2.3347 loss_e_noun 4.5314	
Train: [23][0/126], lr: 0.00003	Time 0.730 (0.730)	Data 0.681 (0.681)	Prec@1 69.531 (69.531)	Prec@1 32.812 (32.812)	Prec@1 28.125 (28.125)	Prec@5 92.969 (92.969)	Prec@5 62.500 (62.500)	Prec@5 61.719 (61.719)	Loss 3.8264 (3.8264)   loss_verb 1.1036   loss_noun 2.6564	beta 0.274, 0.274, 0.183  loss_a 1.9363	gamma 0.003000  loss_e_verb 2.2003 loss_e_noun 4.5197	
Train: [23][50/126], lr: 0.00003	Time 0.093 (0.108)	Data 0.023 (0.036)	Prec@1 63.281 (61.504)	Prec@1 43.750 (39.384)	Prec@1 34.375 (29.473)	Prec@5 87.500 (89.246)	Prec@5 71.875 (68.505)	Prec@5 64.844 (63.833)	Loss 3.8476 (3.8256)   loss_verb 1.3253   loss_noun 2.4820	beta 0.278, 0.278, 0.186  loss_a 1.9117	gamma 0.003000  loss_e_verb 2.3422 loss_e_noun 4.5211	
Train: [23][100/126], lr: 0.00003	Time 0.084 (0.099)	Data 0.017 (0.029)	Prec@1 65.625 (61.262)	Prec@1 35.938 (39.534)	Prec@1 28.125 (29.386)	Prec@5 88.281 (88.722)	Prec@5 64.062 (68.317)	Prec@5 57.812 (63.529)	Loss 3.8497 (3.8326)   loss_verb 1.3376   loss_noun 2.4828	beta 0.283, 0.283, 0.189  loss_a 1.9121	gamma 0.003000  loss_e_verb 2.3423 loss_e_noun 4.5365	
Train: [24][0/126], lr: 0.00003	Time 0.709 (0.709)	Data 0.666 (0.666)	Prec@1 55.469 (55.469)	Prec@1 39.062 (39.062)	Prec@1 28.906 (28.906)	Prec@5 88.281 (88.281)	Prec@5 70.312 (70.312)	Prec@5 65.625 (65.625)	Loss 3.7722 (3.7722)   loss_verb 1.2952   loss_noun 2.3862	beta 0.285, 0.285, 0.190  loss_a 1.9210	gamma 0.003000  loss_e_verb 2.3991 loss_e_noun 4.5797	
Train: [24][50/126], lr: 0.00003	Time 0.086 (0.108)	Data 0.016 (0.033)	Prec@1 66.406 (60.769)	Prec@1 37.500 (39.966)	Prec@1 31.250 (29.657)	Prec@5 89.062 (88.848)	Prec@5 75.000 (69.256)	Prec@5 68.750 (64.629)	Loss 3.7810 (3.8138)   loss_verb 1.3371   loss_noun 2.4493	beta 0.289, 0.289, 0.193  loss_a 1.9104	gamma 0.003000  loss_e_verb 2.3159 loss_e_noun 4.5132	
Train: [24][100/126], lr: 0.00003	Time 0.081 (0.099)	Data 0.016 (0.027)	Prec@1 57.031 (61.456)	Prec@1 36.719 (40.076)	Prec@1 28.125 (29.850)	Prec@5 81.250 (89.124)	Prec@5 64.062 (68.781)	Prec@5 55.469 (64.171)	Loss 4.0193 (3.8159)   loss_verb 1.3210   loss_noun 2.4637	beta 0.293, 0.293, 0.196  loss_a 1.9132	gamma 0.003000  loss_e_verb 2.3131 loss_e_noun 4.5243	
Train: [25][0/126], lr: 0.00003	Time 0.734 (0.734)	Data 0.685 (0.685)	Prec@1 58.594 (58.594)	Prec@1 39.062 (39.062)	Prec@1 29.688 (29.688)	Prec@5 90.625 (90.625)	Prec@5 67.188 (67.188)	Prec@5 63.281 (63.281)	Loss 3.7862 (3.7862)   loss_verb 1.2885   loss_noun 2.4549	beta 0.296, 0.296, 0.197  loss_a 1.9041	gamma 0.003000  loss_e_verb 2.3751 loss_e_noun 4.5141	
Train: [25][50/126], lr: 0.00003	Time 0.088 (0.110)	Data 0.017 (0.035)	Prec@1 57.812 (61.106)	Prec@1 34.375 (40.993)	Prec@1 25.781 (30.392)	Prec@5 87.500 (88.526)	Prec@5 60.156 (68.796)	Prec@5 55.469 (63.802)	Loss 4.0404 (3.8278)   loss_verb 1.3573   loss_noun 2.4436	beta 0.300, 0.300, 0.200  loss_a 1.9171	gamma 0.003000  loss_e_verb 2.3209 loss_e_noun 4.5045	
Train: [25][100/126], lr: 0.00003	Time 0.092 (0.100)	Data 0.028 (0.028)	Prec@1 57.812 (61.587)	Prec@1 47.656 (40.733)	Prec@1 32.031 (30.391)	Prec@5 88.281 (88.784)	Prec@5 71.875 (68.982)	Prec@5 67.188 (64.163)	Loss 3.7876 (3.8156)   loss_verb 1.3416   loss_noun 2.4403	beta 0.304, 0.304, 0.203  loss_a 1.9145	gamma 0.003000  loss_e_verb 2.3195 loss_e_noun 4.5089	
Train: [26][0/126], lr: 0.00003	Time 0.711 (0.711)	Data 0.667 (0.667)	Prec@1 67.188 (67.188)	Prec@1 39.844 (39.844)	Prec@1 29.688 (29.688)	Prec@5 92.188 (92.188)	Prec@5 70.312 (70.312)	Prec@5 67.969 (67.969)	Loss 3.6563 (3.6563)   loss_verb 1.0426   loss_noun 2.3992	beta 0.306, 0.306, 0.204  loss_a 1.9252	gamma 0.003000  loss_e_verb 2.1805 loss_e_noun 4.5805	
Train: [26][50/126], lr: 0.00003	Time 0.089 (0.107)	Data 0.025 (0.036)	Prec@1 55.469 (61.259)	Prec@1 34.375 (39.920)	Prec@1 23.438 (29.672)	Prec@5 87.500 (89.476)	Prec@5 67.188 (68.581)	Prec@5 63.281 (64.032)	Loss 3.9667 (3.8279)   loss_verb 1.3275   loss_noun 2.4735	beta 0.310, 0.310, 0.207  loss_a 1.9171	gamma 0.003000  loss_e_verb 2.3210 loss_e_noun 4.5162	
Train: [26][100/126], lr: 0.00003	Time 0.083 (0.099)	Data 0.018 (0.028)	Prec@1 53.906 (61.301)	Prec@1 38.281 (40.432)	Prec@1 25.781 (29.966)	Prec@5 89.062 (89.295)	Prec@5 61.719 (68.858)	Prec@5 57.812 (64.217)	Loss 4.0124 (3.8226)   loss_verb 1.3341   loss_noun 2.4568	beta 0.314, 0.314, 0.210  loss_a 1.9169	gamma 0.003000  loss_e_verb 2.3256 loss_e_noun 4.5166	
Train: [27][0/126], lr: 0.00003	Time 0.722 (0.722)	Data 0.677 (0.677)	Prec@1 66.406 (66.406)	Prec@1 36.719 (36.719)	Prec@1 26.562 (26.562)	Prec@5 89.062 (89.062)	Prec@5 67.188 (67.188)	Prec@5 60.938 (60.938)	Loss 3.8123 (3.8123)   loss_verb 1.2158   loss_noun 2.5990	beta 0.316, 0.316, 0.211  loss_a 1.8949	gamma 0.003000  loss_e_verb 2.2728 loss_e_noun 4.4370	
Train: [27][50/126], lr: 0.00003	Time 0.100 (0.110)	Data 0.024 (0.036)	Prec@1 60.938 (61.979)	Prec@1 43.750 (39.537)	Prec@1 32.031 (29.289)	Prec@5 88.281 (88.833)	Prec@5 68.750 (68.673)	Prec@5 63.281 (63.817)	Loss 3.8857 (3.8231)   loss_verb 1.3310   loss_noun 2.4661	beta 0.320, 0.320, 0.214  loss_a 1.9143	gamma 0.003000  loss_e_verb 2.3191 loss_e_noun 4.5162	
Train: [27][100/126], lr: 0.00003	Time 0.090 (0.100)	Data 0.021 (0.028)	Prec@1 60.938 (61.154)	Prec@1 45.312 (39.782)	Prec@1 31.250 (29.479)	Prec@5 86.719 (88.916)	Prec@5 75.000 (68.688)	Prec@5 69.531 (63.838)	Loss 3.6549 (3.8348)   loss_verb 1.3435   loss_noun 2.4718	beta 0.325, 0.325, 0.216  loss_a 1.9169	gamma 0.003000  loss_e_verb 2.3177 loss_e_noun 4.5115	
Train: [28][0/126], lr: 0.00003	Time 0.724 (0.724)	Data 0.679 (0.679)	Prec@1 61.719 (61.719)	Prec@1 34.375 (34.375)	Prec@1 24.219 (24.219)	Prec@5 94.531 (94.531)	Prec@5 64.844 (64.844)	Prec@5 64.062 (64.062)	Loss 3.9031 (3.9031)   loss_verb 1.2588   loss_noun 2.6920	beta 0.327, 0.327, 0.218  loss_a 1.9178	gamma 0.003000  loss_e_verb 2.2018 loss_e_noun 4.4296	
Train: [28][50/126], lr: 0.00003	Time 0.093 (0.108)	Data 0.023 (0.035)	Prec@1 62.500 (60.784)	Prec@1 34.375 (40.012)	Prec@1 25.781 (29.688)	Prec@5 92.969 (88.542)	Prec@5 62.500 (68.336)	Prec@5 58.594 (63.802)	Loss 3.7923 (3.8468)   loss_verb 1.3720   loss_noun 2.4722	beta 0.331, 0.331, 0.220  loss_a 1.9145	gamma 0.003000  loss_e_verb 2.3239 loss_e_noun 4.5172	
Train: [28][100/126], lr: 0.00003	Time 0.081 (0.099)	Data 0.020 (0.028)	Prec@1 64.062 (60.798)	Prec@1 36.719 (39.991)	Prec@1 30.469 (29.394)	Prec@5 89.844 (88.946)	Prec@5 64.844 (68.580)	Prec@5 60.938 (64.101)	Loss 3.8951 (3.8318)   loss_verb 1.3449   loss_noun 2.4687	beta 0.335, 0.335, 0.223  loss_a 1.9147	gamma 0.003000  loss_e_verb 2.3279 loss_e_noun 4.5182	
Train: [29][0/126], lr: 0.00003	Time 0.705 (0.705)	Data 0.662 (0.662)	Prec@1 65.625 (65.625)	Prec@1 37.500 (37.500)	Prec@1 28.906 (28.906)	Prec@5 92.188 (92.188)	Prec@5 71.094 (71.094)	Prec@5 67.969 (67.969)	Loss 3.7765 (3.7765)   loss_verb 1.1729   loss_noun 2.4089	beta 0.337, 0.337, 0.224  loss_a 1.9759	gamma 0.003000  loss_e_verb 2.1842 loss_e_noun 4.2937	
Train: [29][50/126], lr: 0.00003	Time 0.089 (0.107)	Data 0.025 (0.035)	Prec@1 60.156 (60.493)	Prec@1 48.438 (39.583)	Prec@1 35.156 (29.105)	Prec@5 90.625 (89.246)	Prec@5 66.406 (67.417)	Prec@5 62.500 (63.205)	Loss 3.8176 (3.8456)   loss_verb 1.3448   loss_noun 2.4942	beta 0.341, 0.341, 0.227  loss_a 1.9159	gamma 0.003000  loss_e_verb 2.3086 loss_e_noun 4.5005	
Train: [29][100/126], lr: 0.00003	Time 0.087 (0.098)	Data 0.019 (0.028)	Prec@1 56.250 (61.139)	Prec@1 35.938 (40.308)	Prec@1 22.656 (29.757)	Prec@5 84.375 (89.086)	Prec@5 64.062 (68.456)	Prec@5 57.812 (64.008)	Loss 4.0373 (3.8235)   loss_verb 1.3344   loss_noun 2.4585	beta 0.345, 0.345, 0.230  loss_a 1.9168	gamma 0.003000  loss_e_verb 2.3064 loss_e_noun 4.5030	
Train: [30][0/126], lr: 0.00003	Time 0.727 (0.727)	Data 0.686 (0.686)	Prec@1 63.281 (63.281)	Prec@1 42.188 (42.188)	Prec@1 35.156 (35.156)	Prec@5 85.156 (85.156)	Prec@5 64.844 (64.844)	Prec@5 60.938 (60.938)	Loss 3.9347 (3.9347)   loss_verb 1.4515   loss_noun 2.5557	beta 0.347, 0.347, 0.231  loss_a 1.9213	gamma 0.003000  loss_e_verb 2.1979 loss_e_noun 4.3690	
Train: [30][50/126], lr: 0.00003	Time 0.097 (0.108)	Data 0.023 (0.036)	Prec@1 57.812 (61.137)	Prec@1 40.625 (40.456)	Prec@1 31.250 (29.856)	Prec@5 87.500 (88.986)	Prec@5 67.188 (69.026)	Prec@5 61.719 (64.200)	Loss 3.8964 (3.8159)   loss_verb 1.3285   loss_noun 2.4470	beta 0.350, 0.350, 0.234  loss_a 1.9179	gamma 0.003000  loss_e_verb 2.3262 loss_e_noun 4.5211	
Train: [30][100/126], lr: 0.00003	Time 0.085 (0.099)	Data 0.017 (0.028)	Prec@1 57.031 (61.023)	Prec@1 40.625 (40.401)	Prec@1 25.781 (29.718)	Prec@5 86.719 (89.024)	Prec@5 60.938 (68.851)	Prec@5 56.250 (64.248)	Loss 4.0101 (3.8166)   loss_verb 1.3289   loss_noun 2.4460	beta 0.354, 0.354, 0.236  loss_a 1.9189	gamma 0.003000  loss_e_verb 2.3206 loss_e_noun 4.5095	
total training time: 359.21112155914307
checkpoint
testing on the test set
preparing the model......
Multi-Scale Temporal Relation Network Module in use ['5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']
loading data......
  0%|          | 0/16 [00:00<?, ?it/s]/home/ac1xliu/experiments/DAAR/epicuda/EPIC-KITCHENS-100_UDA_TA3N/models.py:477: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  base_out = (self.softmax(base_out[0]), self.softmax(base_out[1]))
Testing Results: Prec@1 verb 32.064  Prec@1 noun 13.079 Prec@1 action 8.323 Prec@5 verb 66.873 Prec@5 noun 29.838 Prec@5 action 25.411 Loss 4.99122
