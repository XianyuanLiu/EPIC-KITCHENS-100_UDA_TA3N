(128, 207)
exp_path: model/action-model/Testexp-SGD-share_params_Y-lr_3e-3-bS_128_207/epic-5seg-disDA_none-alpha_0-advDA_RevGrad-beta_0.75_0.75_0.5-useBN_none-addlossDA_attentive_entropy-gamma_0.003-ensDA_none-mu_0-useAttn_TransAttn-n_attn_1/
Flow
Baseline: video
Frame aggregation method: trn-m
target data usage: uSv
Apply the adversarial-based Domain Adaptation approach: RevGrad
preparing the model......
Multi-Scale Temporal Relation Network Module in use ['5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']
using SGD
checking the checkpoint......
loading data......
start training......
Train: [1][0/126], lr: 0.00300	Time 1.026 (1.026)	Data 0.633 (0.633)	Prec@1 0.781 (0.781)	Prec@1 0.000 (0.000)	Prec@1 0.000 (0.000)	Prec@5 4.688 (4.688)	Prec@5 0.781 (0.781)	Prec@5 0.000 (0.000)	Loss 7.2472 (7.2472)   loss_verb 4.5754   loss_noun 5.7043	beta 0.012, 0.012, 0.008  loss_a 2.0812	gamma 0.003000  loss_e_verb 7.7456 loss_e_noun 9.6573	
Train: [1][50/126], lr: 0.00300	Time 0.081 (0.107)	Data 0.013 (0.029)	Prec@1 42.188 (22.381)	Prec@1 10.156 (5.576)	Prec@1 3.125 (1.440)	Prec@5 71.875 (62.592)	Prec@5 35.156 (20.021)	Prec@5 28.906 (13.680)	Loss 5.2992 (6.0536)   loss_verb 3.1307   loss_noun 4.8417	beta 0.017, 0.017, 0.012  loss_a 2.0469	gamma 0.003000  loss_e_verb 5.3219 loss_e_noun 8.3301	
Train: [1][100/126], lr: 0.00300	Time 0.096 (0.098)	Data 0.021 (0.024)	Prec@1 53.125 (32.998)	Prec@1 16.406 (9.615)	Prec@1 10.938 (4.138)	Prec@5 83.594 (69.632)	Prec@5 33.594 (26.694)	Prec@5 32.031 (21.318)	Loss 4.9588 (5.6114)   loss_verb 2.6471   loss_noun 4.4926	beta 0.022, 0.022, 0.015  loss_a 2.0229	gamma 0.003000  loss_e_verb 4.6404 loss_e_noun 7.7907	
Train: [2][0/126], lr: 0.00300	Time 0.652 (0.652)	Data 0.617 (0.617)	Prec@1 47.656 (47.656)	Prec@1 20.312 (20.312)	Prec@1 8.594 (8.594)	Prec@5 78.906 (78.906)	Prec@5 39.062 (39.062)	Prec@5 35.938 (35.938)	Loss 4.8527 (4.8527)   loss_verb 1.9544   loss_noun 3.8077	beta 0.025, 0.025, 0.017  loss_a 1.9572	gamma 0.003000  loss_e_verb 3.2520 loss_e_noun 6.4331	
Train: [2][50/126], lr: 0.00300	Time 0.090 (0.105)	Data 0.024 (0.034)	Prec@1 41.406 (51.900)	Prec@1 24.219 (21.354)	Prec@1 14.844 (13.542)	Prec@5 82.812 (81.449)	Prec@5 42.969 (43.735)	Prec@5 41.406 (39.599)	Loss 4.8197 (4.7280)   loss_verb 1.8476   loss_noun 3.6665	beta 0.030, 0.030, 0.020  loss_a 1.9562	gamma 0.003000  loss_e_verb 3.4029 loss_e_noun 6.4617	
Train: [2][100/126], lr: 0.00300	Time 0.091 (0.097)	Data 0.021 (0.027)	Prec@1 56.250 (51.261)	Prec@1 21.094 (21.720)	Prec@1 16.406 (13.970)	Prec@5 84.375 (81.590)	Prec@5 48.438 (44.199)	Prec@5 46.094 (39.859)	Loss 4.5354 (4.7127)   loss_verb 1.8646   loss_noun 3.6442	beta 0.035, 0.035, 0.023  loss_a 1.9437	gamma 0.003000  loss_e_verb 3.3551 loss_e_noun 6.3794	
Train: [3][0/126], lr: 0.00300	Time 0.693 (0.693)	Data 0.647 (0.647)	Prec@1 53.906 (53.906)	Prec@1 31.250 (31.250)	Prec@1 22.656 (22.656)	Prec@5 82.812 (82.812)	Prec@5 54.688 (54.688)	Prec@5 51.562 (51.562)	Loss 4.3741 (4.3741)   loss_verb 1.7678   loss_noun 3.1629	beta 0.037, 0.037, 0.025  loss_a 1.8953	gamma 0.003000  loss_e_verb 3.0122 loss_e_noun 5.9593	
Train: [3][50/126], lr: 0.00300	Time 0.095 (0.107)	Data 0.023 (0.034)	Prec@1 53.125 (53.998)	Prec@1 24.219 (25.751)	Prec@1 19.531 (17.570)	Prec@5 81.250 (83.915)	Prec@5 48.438 (49.081)	Prec@5 45.312 (45.083)	Loss 4.4763 (4.4933)   loss_verb 1.7259   loss_noun 3.4003	beta 0.042, 0.042, 0.028  loss_a 1.9166	gamma 0.003000  loss_e_verb 3.0948 loss_e_noun 5.9722	
Train: [3][100/126], lr: 0.00300	Time 0.090 (0.098)	Data 0.016 (0.027)	Prec@1 62.500 (54.200)	Prec@1 28.906 (25.990)	Prec@1 23.438 (17.652)	Prec@5 86.719 (84.244)	Prec@5 57.031 (49.768)	Prec@5 53.906 (45.552)	Loss 4.2503 (4.4801)   loss_verb 1.7006   loss_noun 3.3859	beta 0.047, 0.047, 0.032  loss_a 1.9232	gamma 0.003000  loss_e_verb 3.1044 loss_e_noun 5.9802	
Train: [4][0/126], lr: 0.00300	Time 0.685 (0.685)	Data 0.643 (0.643)	Prec@1 56.250 (56.250)	Prec@1 30.469 (30.469)	Prec@1 21.094 (21.094)	Prec@5 90.625 (90.625)	Prec@5 56.250 (56.250)	Prec@5 52.344 (52.344)	Loss 4.1676 (4.1676)   loss_verb 1.4306   loss_noun 3.1289	beta 0.050, 0.050, 0.033  loss_a 1.8743	gamma 0.003000  loss_e_verb 2.9736 loss_e_noun 6.0463	
Train: [4][50/126], lr: 0.00300	Time 0.091 (0.106)	Data 0.022 (0.035)	Prec@1 52.344 (56.081)	Prec@1 36.719 (29.151)	Prec@1 21.875 (20.175)	Prec@5 83.594 (85.861)	Prec@5 57.812 (53.401)	Prec@5 51.562 (49.295)	Loss 4.2014 (4.3301)   loss_verb 1.6001   loss_noun 3.2041	beta 0.055, 0.055, 0.037  loss_a 1.9149	gamma 0.003000  loss_e_verb 2.9810 loss_e_noun 5.8164	
Train: [4][100/126], lr: 0.00300	Time 0.085 (0.097)	Data 0.020 (0.028)	Prec@1 56.250 (55.825)	Prec@1 29.688 (28.837)	Prec@1 22.656 (19.779)	Prec@5 81.250 (85.682)	Prec@5 59.375 (53.775)	Prec@5 50.781 (49.373)	Loss 4.3523 (4.3394)   loss_verb 1.6156   loss_noun 3.2113	beta 0.060, 0.060, 0.040  loss_a 1.9127	gamma 0.003000  loss_e_verb 2.9948 loss_e_noun 5.8004	
Train: [5][0/126], lr: 0.00300	Time 0.705 (0.705)	Data 0.661 (0.661)	Prec@1 57.812 (57.812)	Prec@1 29.688 (29.688)	Prec@1 19.531 (19.531)	Prec@5 88.281 (88.281)	Prec@5 62.500 (62.500)	Prec@5 57.031 (57.031)	Loss 4.1621 (4.1621)   loss_verb 1.4720   loss_noun 2.9488	beta 0.062, 0.062, 0.042  loss_a 1.9388	gamma 0.003000  loss_e_verb 2.9694 loss_e_noun 5.6444	
Train: [5][50/126], lr: 0.00300	Time 0.091 (0.107)	Data 0.016 (0.036)	Prec@1 57.031 (57.322)	Prec@1 42.188 (31.464)	Prec@1 27.344 (22.258)	Prec@5 89.844 (86.872)	Prec@5 64.062 (57.047)	Prec@5 58.594 (52.972)	Loss 3.9878 (4.2279)   loss_verb 1.5352   loss_noun 3.0503	beta 0.067, 0.067, 0.045  loss_a 1.9224	gamma 0.003000  loss_e_verb 2.8782 loss_e_noun 5.6220	
Train: [5][100/126], lr: 0.00300	Time 0.088 (0.098)	Data 0.017 (0.029)	Prec@1 62.500 (57.774)	Prec@1 32.812 (31.033)	Prec@1 25.000 (21.782)	Prec@5 85.938 (86.657)	Prec@5 60.156 (56.691)	Prec@5 53.125 (52.313)	Loss 4.1524 (4.2473)   loss_verb 1.5374   loss_noun 3.0673	beta 0.072, 0.072, 0.048  loss_a 1.9322	gamma 0.003000  loss_e_verb 2.8901 loss_e_noun 5.6214	
Train: [6][0/126], lr: 0.00300	Time 0.710 (0.710)	Data 0.660 (0.660)	Prec@1 58.594 (58.594)	Prec@1 27.344 (27.344)	Prec@1 20.312 (20.312)	Prec@5 85.156 (85.156)	Prec@5 56.250 (56.250)	Prec@5 50.781 (50.781)	Loss 4.2215 (4.2215)   loss_verb 1.5013   loss_noun 3.0189	beta 0.075, 0.075, 0.050  loss_a 1.9484	gamma 0.003000  loss_e_verb 2.8517 loss_e_noun 5.8391	
Train: [6][50/126], lr: 0.00300	Time 0.079 (0.106)	Data 0.017 (0.035)	Prec@1 67.188 (59.896)	Prec@1 30.469 (32.001)	Prec@1 21.875 (22.947)	Prec@5 89.844 (88.082)	Prec@5 62.500 (58.701)	Prec@5 59.375 (54.381)	Loss 4.0037 (4.1674)   loss_verb 1.4304   loss_noun 2.9678	beta 0.080, 0.080, 0.053  loss_a 1.9560	gamma 0.003000  loss_e_verb 2.7516 loss_e_noun 5.4355	
Train: [6][100/126], lr: 0.00300	Time 0.086 (0.098)	Data 0.020 (0.028)	Prec@1 58.594 (59.166)	Prec@1 29.688 (32.256)	Prec@1 20.312 (22.927)	Prec@5 85.938 (87.601)	Prec@5 60.156 (59.011)	Prec@5 53.125 (54.548)	Loss 4.2190 (4.1891)   loss_verb 1.4652   loss_noun 2.9616	beta 0.085, 0.085, 0.056  loss_a 1.9633	gamma 0.003000  loss_e_verb 2.7789 loss_e_noun 5.4392	
Train: [7][0/126], lr: 0.00300	Time 0.700 (0.700)	Data 0.665 (0.665)	Prec@1 59.375 (59.375)	Prec@1 32.812 (32.812)	Prec@1 25.000 (25.000)	Prec@5 89.062 (89.062)	Prec@5 60.156 (60.156)	Prec@5 55.469 (55.469)	Loss 4.1046 (4.1046)   loss_verb 1.3849   loss_noun 2.9253	beta 0.087, 0.087, 0.058  loss_a 1.9368	gamma 0.003000  loss_e_verb 2.9723 loss_e_noun 5.5252	
Train: [7][50/126], lr: 0.00300	Time 0.080 (0.107)	Data 0.017 (0.034)	Prec@1 57.812 (59.988)	Prec@1 32.812 (33.287)	Prec@1 25.000 (23.974)	Prec@5 86.719 (88.480)	Prec@5 65.625 (60.846)	Prec@5 59.375 (56.909)	Loss 4.1838 (4.1207)   loss_verb 1.4224   loss_noun 2.8632	beta 0.092, 0.092, 0.061  loss_a 1.9658	gamma 0.003000  loss_e_verb 2.7320 loss_e_noun 5.3561	
Train: [7][100/126], lr: 0.00300	Time 0.077 (0.098)	Data 0.017 (0.027)	Prec@1 67.188 (59.824)	Prec@1 31.250 (33.694)	Prec@1 22.656 (24.389)	Prec@5 89.062 (88.351)	Prec@5 59.375 (60.852)	Prec@5 55.469 (56.691)	Loss 4.1297 (4.1211)   loss_verb 1.4263   loss_noun 2.8682	beta 0.097, 0.097, 0.065  loss_a 1.9618	gamma 0.003000  loss_e_verb 2.7129 loss_e_noun 5.3295	
Train: [8][0/126], lr: 0.00300	Time 0.714 (0.714)	Data 0.662 (0.662)	Prec@1 55.469 (55.469)	Prec@1 38.281 (38.281)	Prec@1 26.562 (26.562)	Prec@5 87.500 (87.500)	Prec@5 64.844 (64.844)	Prec@5 59.375 (59.375)	Loss 4.1398 (4.1398)   loss_verb 1.5185   loss_noun 2.8574	beta 0.099, 0.099, 0.066  loss_a 1.9396	gamma 0.003000  loss_e_verb 2.8553 loss_e_noun 5.3017	
Train: [8][50/126], lr: 0.00300	Time 0.092 (0.108)	Data 0.027 (0.034)	Prec@1 58.594 (60.692)	Prec@1 35.156 (35.003)	Prec@1 27.344 (25.368)	Prec@5 92.188 (89.246)	Prec@5 65.625 (62.086)	Prec@5 63.281 (58.180)	Loss 4.0075 (4.0641)   loss_verb 1.3759   loss_noun 2.8106	beta 0.104, 0.104, 0.070  loss_a 1.9593	gamma 0.003000  loss_e_verb 2.5911 loss_e_noun 5.1847	
Train: [8][100/126], lr: 0.00300	Time 0.093 (0.099)	Data 0.020 (0.028)	Prec@1 64.844 (60.860)	Prec@1 43.750 (34.715)	Prec@1 30.469 (25.201)	Prec@5 89.844 (89.287)	Prec@5 64.062 (61.665)	Prec@5 59.375 (57.789)	Loss 3.8849 (4.0664)   loss_verb 1.3798   loss_noun 2.8209	beta 0.109, 0.109, 0.073  loss_a 1.9543	gamma 0.003000  loss_e_verb 2.6087 loss_e_noun 5.1925	
Train: [9][0/126], lr: 0.00300	Time 0.695 (0.695)	Data 0.648 (0.648)	Prec@1 60.156 (60.156)	Prec@1 35.156 (35.156)	Prec@1 24.219 (24.219)	Prec@5 89.062 (89.062)	Prec@5 56.250 (56.250)	Prec@5 52.344 (52.344)	Loss 4.1188 (4.1188)   loss_verb 1.4065   loss_noun 2.8463	beta 0.112, 0.112, 0.074  loss_a 1.9804	gamma 0.003000  loss_e_verb 2.7191 loss_e_noun 5.2897	
Train: [9][50/126], lr: 0.00300	Time 0.087 (0.111)	Data 0.018 (0.033)	Prec@1 53.906 (60.218)	Prec@1 33.594 (35.585)	Prec@1 24.219 (25.031)	Prec@5 87.500 (89.415)	Prec@5 56.250 (62.806)	Prec@5 50.781 (58.701)	Loss 4.2761 (4.0311)   loss_verb 1.3716   loss_noun 2.7654	beta 0.117, 0.117, 0.078  loss_a 1.9510	gamma 0.003000  loss_e_verb 2.5705 loss_e_noun 5.1012	
Train: [9][100/126], lr: 0.00300	Time 0.094 (0.100)	Data 0.023 (0.028)	Prec@1 69.531 (60.798)	Prec@1 34.375 (35.852)	Prec@1 27.344 (25.766)	Prec@5 92.969 (89.619)	Prec@5 58.594 (63.328)	Prec@5 55.469 (59.344)	Loss 3.9821 (4.0107)   loss_verb 1.3553   loss_noun 2.7447	beta 0.121, 0.121, 0.081  loss_a 1.9492	gamma 0.003000  loss_e_verb 2.5529 loss_e_noun 5.0727	
Train: [10][0/126], lr: 0.00030	Time 0.704 (0.704)	Data 0.658 (0.658)	Prec@1 65.625 (65.625)	Prec@1 45.312 (45.312)	Prec@1 32.812 (32.812)	Prec@5 92.969 (92.969)	Prec@5 73.438 (73.438)	Prec@5 71.875 (71.875)	Loss 3.6271 (3.6271)   loss_verb 1.1366   loss_noun 2.2363	beta 0.124, 0.124, 0.083  loss_a 1.9297	gamma 0.003000  loss_e_verb 2.4845 loss_e_noun 4.8198	
Train: [10][50/126], lr: 0.00030	Time 0.096 (0.111)	Data 0.018 (0.033)	Prec@1 65.625 (63.373)	Prec@1 31.250 (37.852)	Prec@1 20.312 (27.420)	Prec@5 90.625 (90.456)	Prec@5 62.500 (65.824)	Prec@5 58.594 (61.933)	Loss 4.0979 (3.9065)   loss_verb 1.2858   loss_noun 2.6206	beta 0.129, 0.129, 0.086  loss_a 1.9421	gamma 0.003000  loss_e_verb 2.4875 loss_e_noun 5.0073	
Train: [10][100/126], lr: 0.00030	Time 0.094 (0.101)	Data 0.021 (0.026)	Prec@1 56.250 (64.132)	Prec@1 32.812 (38.413)	Prec@1 25.000 (28.605)	Prec@5 89.062 (90.517)	Prec@5 55.469 (65.880)	Prec@5 53.906 (62.036)	Loss 4.1365 (3.8814)   loss_verb 1.2585   loss_noun 2.6004	beta 0.133, 0.133, 0.089  loss_a 1.9408	gamma 0.003000  loss_e_verb 2.4790 loss_e_noun 4.9750	
Train: [11][0/126], lr: 0.00030	Time 0.682 (0.682)	Data 0.637 (0.637)	Prec@1 66.406 (66.406)	Prec@1 40.625 (40.625)	Prec@1 32.031 (32.031)	Prec@5 91.406 (91.406)	Prec@5 71.875 (71.875)	Prec@5 65.625 (65.625)	Loss 3.7502 (3.7502)   loss_verb 1.2429   loss_noun 2.3254	beta 0.136, 0.136, 0.091  loss_a 1.9549	gamma 0.003000  loss_e_verb 2.5625 loss_e_noun 4.8506	
Train: [11][50/126], lr: 0.00030	Time 0.088 (0.106)	Data 0.017 (0.034)	Prec@1 75.781 (64.874)	Prec@1 36.719 (39.828)	Prec@1 32.812 (29.902)	Prec@5 91.406 (90.365)	Prec@5 71.875 (67.341)	Prec@5 67.969 (63.450)	Loss 3.6526 (3.8368)   loss_verb 1.2385   loss_noun 2.5332	beta 0.141, 0.141, 0.094  loss_a 1.9400	gamma 0.003000  loss_e_verb 2.4277 loss_e_noun 4.8898	
Train: [11][100/126], lr: 0.00030	Time 0.081 (0.097)	Data 0.017 (0.027)	Prec@1 67.969 (64.627)	Prec@1 42.969 (39.650)	Prec@1 32.812 (29.657)	Prec@5 88.281 (90.718)	Prec@5 68.750 (67.071)	Prec@5 62.500 (63.250)	Loss 3.6940 (3.8405)   loss_verb 1.2302   loss_noun 2.5460	beta 0.146, 0.146, 0.097  loss_a 1.9414	gamma 0.003000  loss_e_verb 2.4245 loss_e_noun 4.8817	
Train: [12][0/126], lr: 0.00030	Time 0.699 (0.699)	Data 0.646 (0.646)	Prec@1 66.406 (66.406)	Prec@1 46.094 (46.094)	Prec@1 35.156 (35.156)	Prec@5 85.156 (85.156)	Prec@5 68.750 (68.750)	Prec@5 64.844 (64.844)	Loss 3.8502 (3.8502)   loss_verb 1.2555   loss_noun 2.5236	beta 0.148, 0.148, 0.099  loss_a 1.9495	gamma 0.003000  loss_e_verb 2.4951 loss_e_noun 4.9271	
Train: [12][50/126], lr: 0.00030	Time 0.083 (0.107)	Data 0.018 (0.035)	Prec@1 64.062 (64.583)	Prec@1 36.719 (40.365)	Prec@1 27.344 (30.316)	Prec@5 90.625 (90.794)	Prec@5 68.750 (67.754)	Prec@5 64.062 (63.680)	Loss 3.8659 (3.8344)   loss_verb 1.2325   loss_noun 2.5291	beta 0.153, 0.153, 0.102  loss_a 1.9426	gamma 0.003000  loss_e_verb 2.4430 loss_e_noun 4.9045	
Train: [12][100/126], lr: 0.00030	Time 0.092 (0.098)	Data 0.022 (0.028)	Prec@1 64.062 (64.596)	Prec@1 39.062 (40.494)	Prec@1 30.469 (30.384)	Prec@5 83.594 (90.981)	Prec@5 60.938 (67.543)	Prec@5 57.031 (63.699)	Loss 4.1375 (3.8272)   loss_verb 1.2249   loss_noun 2.5250	beta 0.158, 0.158, 0.105  loss_a 1.9413	gamma 0.003000  loss_e_verb 2.4140 loss_e_noun 4.8665	
Train: [13][0/126], lr: 0.00030	Time 0.682 (0.682)	Data 0.631 (0.631)	Prec@1 65.625 (65.625)	Prec@1 35.156 (35.156)	Prec@1 28.125 (28.125)	Prec@5 88.281 (88.281)	Prec@5 67.969 (67.969)	Prec@5 62.500 (62.500)	Loss 3.8904 (3.8904)   loss_verb 1.2602   loss_noun 2.6553	beta 0.160, 0.160, 0.107  loss_a 1.9223	gamma 0.003000  loss_e_verb 2.2851 loss_e_noun 4.6872	
Train: [13][50/126], lr: 0.00030	Time 0.095 (0.106)	Data 0.021 (0.034)	Prec@1 70.312 (65.028)	Prec@1 34.375 (38.925)	Prec@1 28.906 (29.151)	Prec@5 92.188 (90.426)	Prec@5 64.062 (66.330)	Prec@5 61.719 (62.515)	Loss 3.8824 (3.8534)   loss_verb 1.2337   loss_noun 2.5690	beta 0.165, 0.165, 0.110  loss_a 1.9412	gamma 0.003000  loss_e_verb 2.3909 loss_e_noun 4.8651	
Train: [13][100/126], lr: 0.00030	Time 0.095 (0.098)	Data 0.023 (0.027)	Prec@1 60.938 (65.347)	Prec@1 40.625 (39.596)	Prec@1 30.469 (29.997)	Prec@5 91.406 (90.780)	Prec@5 69.531 (66.847)	Prec@5 67.969 (63.157)	Loss 3.7851 (3.8291)   loss_verb 1.2095   loss_noun 2.5393	beta 0.169, 0.169, 0.113  loss_a 1.9439	gamma 0.003000  loss_e_verb 2.3807 loss_e_noun 4.8540	
Train: [14][0/126], lr: 0.00030	Time 0.730 (0.730)	Data 0.679 (0.679)	Prec@1 61.719 (61.719)	Prec@1 38.281 (38.281)	Prec@1 25.781 (25.781)	Prec@5 91.406 (91.406)	Prec@5 63.281 (63.281)	Prec@5 59.375 (59.375)	Loss 3.9159 (3.9159)   loss_verb 1.2265   loss_noun 2.6396	beta 0.172, 0.172, 0.115  loss_a 1.9717	gamma 0.003000  loss_e_verb 2.4162 loss_e_noun 4.9761	
Train: [14][50/126], lr: 0.00030	Time 0.090 (0.107)	Data 0.022 (0.036)	Prec@1 69.531 (65.610)	Prec@1 40.625 (40.901)	Prec@1 32.812 (30.928)	Prec@5 91.406 (91.544)	Prec@5 67.188 (67.525)	Prec@5 63.281 (63.833)	Loss 3.7897 (3.8012)   loss_verb 1.1842   loss_noun 2.5037	beta 0.177, 0.177, 0.118  loss_a 1.9465	gamma 0.003000  loss_e_verb 2.3880 loss_e_noun 4.8296	
Train: [14][100/126], lr: 0.00030	Time 0.092 (0.098)	Data 0.026 (0.028)	Prec@1 63.281 (65.455)	Prec@1 41.406 (40.780)	Prec@1 34.375 (30.972)	Prec@5 88.281 (91.259)	Prec@5 64.844 (67.512)	Prec@5 63.281 (63.807)	Loss 3.8781 (3.8059)   loss_verb 1.1936   loss_noun 2.5043	beta 0.181, 0.181, 0.121  loss_a 1.9461	gamma 0.003000  loss_e_verb 2.3842 loss_e_noun 4.8143	
Train: [15][0/126], lr: 0.00030	Time 0.691 (0.691)	Data 0.647 (0.647)	Prec@1 59.375 (59.375)	Prec@1 42.188 (42.188)	Prec@1 29.688 (29.688)	Prec@5 92.969 (92.969)	Prec@5 66.406 (66.406)	Prec@5 64.062 (64.062)	Loss 3.8233 (3.8233)   loss_verb 1.1465   loss_noun 2.5909	beta 0.184, 0.184, 0.122  loss_a 1.9438	gamma 0.003000  loss_e_verb 2.2870 loss_e_noun 4.8872	
Train: [15][50/126], lr: 0.00030	Time 0.089 (0.106)	Data 0.017 (0.036)	Prec@1 62.500 (65.334)	Prec@1 42.188 (40.794)	Prec@1 34.375 (30.882)	Prec@5 89.062 (91.651)	Prec@5 68.750 (67.984)	Prec@5 67.188 (64.384)	Loss 3.7133 (3.7913)   loss_verb 1.1833   loss_noun 2.4810	beta 0.188, 0.188, 0.126  loss_a 1.9484	gamma 0.003000  loss_e_verb 2.3770 loss_e_noun 4.7931	
Train: [15][100/126], lr: 0.00030	Time 0.091 (0.098)	Data 0.022 (0.028)	Prec@1 69.531 (65.617)	Prec@1 41.406 (40.749)	Prec@1 31.250 (30.972)	Prec@5 87.500 (91.329)	Prec@5 66.406 (67.505)	Prec@5 60.156 (63.861)	Loss 3.7535 (3.8065)   loss_verb 1.1882   loss_noun 2.5040	beta 0.193, 0.193, 0.129  loss_a 1.9497	gamma 0.003000  loss_e_verb 2.3541 loss_e_noun 4.7881	
Train: [16][0/126], lr: 0.00030	Time 0.722 (0.722)	Data 0.676 (0.676)	Prec@1 67.969 (67.969)	Prec@1 41.406 (41.406)	Prec@1 30.469 (30.469)	Prec@5 92.188 (92.188)	Prec@5 70.312 (70.312)	Prec@5 66.406 (66.406)	Loss 3.6973 (3.6973)   loss_verb 1.1226   loss_noun 2.3063	beta 0.195, 0.195, 0.130  loss_a 1.9725	gamma 0.003000  loss_e_verb 2.2393 loss_e_noun 4.6688	
Train: [16][50/126], lr: 0.00030	Time 0.091 (0.106)	Data 0.027 (0.035)	Prec@1 56.250 (66.008)	Prec@1 43.750 (41.222)	Prec@1 30.469 (31.556)	Prec@5 85.938 (91.559)	Prec@5 71.875 (68.735)	Prec@5 66.406 (65.334)	Loss 3.8390 (3.7717)   loss_verb 1.1795   loss_noun 2.4451	beta 0.200, 0.200, 0.133  loss_a 1.9486	gamma 0.003000  loss_e_verb 2.3846 loss_e_noun 4.7581	
Train: [16][100/126], lr: 0.00030	Time 0.088 (0.098)	Data 0.015 (0.028)	Prec@1 67.969 (65.911)	Prec@1 35.938 (41.058)	Prec@1 28.906 (31.467)	Prec@5 92.969 (91.120)	Prec@5 66.406 (68.317)	Prec@5 64.062 (64.565)	Loss 3.8429 (3.7897)   loss_verb 1.1867   loss_noun 2.4720	beta 0.205, 0.205, 0.136  loss_a 1.9497	gamma 0.003000  loss_e_verb 2.3765 loss_e_noun 4.7745	
Train: [17][0/126], lr: 0.00030	Time 0.695 (0.695)	Data 0.645 (0.645)	Prec@1 65.625 (65.625)	Prec@1 44.531 (44.531)	Prec@1 34.375 (34.375)	Prec@5 92.969 (92.969)	Prec@5 68.750 (68.750)	Prec@5 64.844 (64.844)	Loss 3.6606 (3.6606)   loss_verb 1.1103   loss_noun 2.2956	beta 0.207, 0.207, 0.138  loss_a 1.9468	gamma 0.003000  loss_e_verb 2.4416 loss_e_noun 4.7682	
Train: [17][50/126], lr: 0.00030	Time 0.079 (0.106)	Data 0.017 (0.036)	Prec@1 67.969 (65.196)	Prec@1 42.188 (40.993)	Prec@1 30.469 (30.760)	Prec@5 90.625 (91.238)	Prec@5 71.094 (68.781)	Prec@5 67.969 (64.890)	Loss 3.6957 (3.7897)   loss_verb 1.2012   loss_noun 2.4454	beta 0.212, 0.212, 0.141  loss_a 1.9557	gamma 0.003000  loss_e_verb 2.3909 loss_e_noun 4.7766	
Train: [17][100/126], lr: 0.00030	Time 0.088 (0.098)	Data 0.016 (0.028)	Prec@1 61.719 (65.865)	Prec@1 37.500 (41.143)	Prec@1 29.688 (30.964)	Prec@5 92.969 (91.538)	Prec@5 68.750 (68.680)	Prec@5 65.625 (65.014)	Loss 3.7801 (3.7877)   loss_verb 1.1767   loss_noun 2.4693	beta 0.216, 0.216, 0.144  loss_a 1.9539	gamma 0.003000  loss_e_verb 2.3763 loss_e_noun 4.7807	
Train: [18][0/126], lr: 0.00030	Time 0.724 (0.724)	Data 0.675 (0.675)	Prec@1 68.750 (68.750)	Prec@1 42.969 (42.969)	Prec@1 35.156 (35.156)	Prec@5 92.969 (92.969)	Prec@5 63.281 (63.281)	Prec@5 60.938 (60.938)	Loss 3.7472 (3.7472)   loss_verb 1.0064   loss_noun 2.5298	beta 0.218, 0.218, 0.146  loss_a 1.9686	gamma 0.003000  loss_e_verb 2.2102 loss_e_noun 4.7625	
Train: [18][50/126], lr: 0.00030	Time 0.083 (0.107)	Data 0.024 (0.035)	Prec@1 57.812 (65.885)	Prec@1 42.969 (42.034)	Prec@1 25.781 (32.031)	Prec@5 93.750 (91.498)	Prec@5 68.750 (68.627)	Prec@5 65.625 (64.782)	Loss 3.8899 (3.7868)   loss_verb 1.1823   loss_noun 2.4600	beta 0.223, 0.223, 0.149  loss_a 1.9549	gamma 0.003000  loss_e_verb 2.3559 loss_e_noun 4.7737	
Train: [18][100/126], lr: 0.00030	Time 0.090 (0.098)	Data 0.025 (0.028)	Prec@1 64.062 (65.787)	Prec@1 46.875 (41.692)	Prec@1 35.938 (31.675)	Prec@5 92.188 (91.136)	Prec@5 75.000 (68.827)	Prec@5 72.656 (64.921)	Loss 3.6619 (3.7857)   loss_verb 1.1911   loss_noun 2.4506	beta 0.228, 0.228, 0.152  loss_a 1.9542	gamma 0.003000  loss_e_verb 2.3517 loss_e_noun 4.7589	
Train: [19][0/126], lr: 0.00030	Time 0.738 (0.738)	Data 0.690 (0.690)	Prec@1 67.188 (67.188)	Prec@1 46.094 (46.094)	Prec@1 32.812 (32.812)	Prec@5 92.969 (92.969)	Prec@5 69.531 (69.531)	Prec@5 67.188 (67.188)	Loss 3.6323 (3.6323)   loss_verb 1.0681   loss_noun 2.3170	beta 0.230, 0.230, 0.153  loss_a 1.9293	gamma 0.003000  loss_e_verb 2.3000 loss_e_noun 4.6638	
Train: [19][50/126], lr: 0.00030	Time 0.089 (0.107)	Data 0.025 (0.036)	Prec@1 67.188 (65.778)	Prec@1 42.188 (41.299)	Prec@1 33.594 (31.495)	Prec@5 92.969 (91.192)	Prec@5 62.500 (68.536)	Prec@5 60.156 (64.813)	Loss 3.8353 (3.7910)   loss_verb 1.1839   loss_noun 2.4696	beta 0.234, 0.234, 0.156  loss_a 1.9535	gamma 0.003000  loss_e_verb 2.3576 loss_e_noun 4.7798	
Train: [19][100/126], lr: 0.00030	Time 0.094 (0.098)	Data 0.023 (0.029)	Prec@1 69.531 (65.950)	Prec@1 33.594 (41.615)	Prec@1 28.906 (31.768)	Prec@5 89.844 (91.375)	Prec@5 64.844 (68.433)	Prec@5 60.938 (64.821)	Loss 3.8926 (3.7847)   loss_verb 1.1794   loss_noun 2.4602	beta 0.239, 0.239, 0.159  loss_a 1.9542	gamma 0.003000  loss_e_verb 2.3357 loss_e_noun 4.7422	
Train: [20][0/126], lr: 0.00003	Time 0.708 (0.708)	Data 0.669 (0.669)	Prec@1 72.656 (72.656)	Prec@1 46.875 (46.875)	Prec@1 35.938 (35.938)	Prec@5 94.531 (94.531)	Prec@5 75.781 (75.781)	Prec@5 72.656 (72.656)	Loss 3.5905 (3.5905)   loss_verb 1.0198   loss_noun 2.2086	beta 0.241, 0.241, 0.161  loss_a 1.9658	gamma 0.003000  loss_e_verb 2.2921 loss_e_noun 4.6986	
Train: [20][50/126], lr: 0.00003	Time 0.092 (0.107)	Data 0.026 (0.035)	Prec@1 72.656 (67.525)	Prec@1 42.188 (42.279)	Prec@1 34.375 (32.889)	Prec@5 91.406 (92.096)	Prec@5 67.969 (68.857)	Prec@5 63.281 (65.564)	Loss 3.6367 (3.7547)   loss_verb 1.1327   loss_noun 2.4490	beta 0.246, 0.246, 0.164  loss_a 1.9532	gamma 0.003000  loss_e_verb 2.3757 loss_e_noun 4.7803	
Train: [20][100/126], lr: 0.00003	Time 0.097 (0.098)	Data 0.027 (0.028)	Prec@1 64.844 (66.832)	Prec@1 40.625 (42.458)	Prec@1 32.031 (32.828)	Prec@5 91.406 (92.033)	Prec@5 68.750 (68.866)	Prec@5 60.938 (65.331)	Loss 3.8114 (3.7566)   loss_verb 1.1453   loss_noun 2.4365	beta 0.250, 0.250, 0.167  loss_a 1.9550	gamma 0.003000  loss_e_verb 2.3770 loss_e_noun 4.7878	
Train: [21][0/126], lr: 0.00003	Time 0.718 (0.718)	Data 0.670 (0.670)	Prec@1 67.969 (67.969)	Prec@1 39.062 (39.062)	Prec@1 32.031 (32.031)	Prec@5 88.281 (88.281)	Prec@5 59.375 (59.375)	Prec@5 57.031 (57.031)	Loss 4.0077 (4.0077)   loss_verb 1.2704   loss_noun 2.7991	beta 0.252, 0.252, 0.168  loss_a 1.9620	gamma 0.003000  loss_e_verb 2.4358 loss_e_noun 4.8504	
Train: [21][50/126], lr: 0.00003	Time 0.082 (0.109)	Data 0.015 (0.035)	Prec@1 68.750 (66.774)	Prec@1 47.656 (40.594)	Prec@1 35.938 (31.143)	Prec@5 92.188 (91.544)	Prec@5 62.500 (67.616)	Prec@5 60.938 (64.078)	Loss 3.7543 (3.7956)   loss_verb 1.1599   loss_noun 2.4957	beta 0.257, 0.257, 0.171  loss_a 1.9570	gamma 0.003000  loss_e_verb 2.3602 loss_e_noun 4.7827	
Train: [21][100/126], lr: 0.00003	Time 0.078 (0.099)	Data 0.017 (0.028)	Prec@1 66.406 (66.623)	Prec@1 43.750 (41.429)	Prec@1 32.812 (31.853)	Prec@5 89.062 (91.615)	Prec@5 63.281 (68.758)	Prec@5 58.594 (65.076)	Loss 3.8613 (3.7669)   loss_verb 1.1535   loss_noun 2.4518	beta 0.261, 0.261, 0.174  loss_a 1.9536	gamma 0.003000  loss_e_verb 2.3560 loss_e_noun 4.7706	
Train: [22][0/126], lr: 0.00003	Time 0.709 (0.709)	Data 0.672 (0.672)	Prec@1 64.062 (64.062)	Prec@1 42.188 (42.188)	Prec@1 31.250 (31.250)	Prec@5 87.500 (87.500)	Prec@5 69.531 (69.531)	Prec@5 63.281 (63.281)	Loss 3.8662 (3.8662)   loss_verb 1.3216   loss_noun 2.4452	beta 0.263, 0.263, 0.176  loss_a 1.9723	gamma 0.003000  loss_e_verb 2.3444 loss_e_noun 4.6923	
Train: [22][50/126], lr: 0.00003	Time 0.097 (0.110)	Data 0.019 (0.034)	Prec@1 63.281 (66.023)	Prec@1 42.188 (41.820)	Prec@1 28.125 (31.909)	Prec@5 92.188 (92.111)	Prec@5 64.844 (68.964)	Prec@5 60.938 (65.502)	Loss 3.7577 (3.7612)   loss_verb 1.1548   loss_noun 2.4414	beta 0.268, 0.268, 0.178  loss_a 1.9524	gamma 0.003000  loss_e_verb 2.3413 loss_e_noun 4.7560	
Train: [22][100/126], lr: 0.00003	Time 0.082 (0.100)	Data 0.018 (0.027)	Prec@1 71.094 (66.422)	Prec@1 48.438 (42.087)	Prec@1 40.625 (32.178)	Prec@5 91.406 (91.824)	Prec@5 68.750 (69.230)	Prec@5 65.625 (65.702)	Loss 3.6404 (3.7614)   loss_verb 1.1575   loss_noun 2.4371	beta 0.272, 0.272, 0.181  loss_a 1.9535	gamma 0.003000  loss_e_verb 2.3344 loss_e_noun 4.7560	
Train: [23][0/126], lr: 0.00003	Time 0.725 (0.725)	Data 0.669 (0.669)	Prec@1 65.625 (65.625)	Prec@1 42.188 (42.188)	Prec@1 31.250 (31.250)	Prec@5 93.750 (93.750)	Prec@5 69.531 (69.531)	Prec@5 65.625 (65.625)	Loss 3.7290 (3.7290)   loss_verb 1.0586   loss_noun 2.4911	beta 0.274, 0.274, 0.183  loss_a 1.9435	gamma 0.003000  loss_e_verb 2.3319 loss_e_noun 4.8036	
Train: [23][50/126], lr: 0.00003	Time 0.093 (0.107)	Data 0.021 (0.036)	Prec@1 62.500 (66.544)	Prec@1 46.875 (42.279)	Prec@1 33.594 (31.985)	Prec@5 90.625 (91.866)	Prec@5 75.000 (68.474)	Prec@5 70.312 (64.752)	Loss 3.7276 (3.7594)   loss_verb 1.1385   loss_noun 2.4537	beta 0.278, 0.278, 0.186  loss_a 1.9527	gamma 0.003000  loss_e_verb 2.3373 loss_e_noun 4.7563	
Train: [23][100/126], lr: 0.00003	Time 0.092 (0.098)	Data 0.022 (0.028)	Prec@1 66.406 (66.484)	Prec@1 44.531 (42.659)	Prec@1 33.594 (32.356)	Prec@5 92.188 (91.638)	Prec@5 69.531 (68.835)	Prec@5 64.062 (65.114)	Loss 3.8105 (3.7595)   loss_verb 1.1484   loss_noun 2.4426	beta 0.283, 0.283, 0.189  loss_a 1.9533	gamma 0.003000  loss_e_verb 2.3386 loss_e_noun 4.7523	
Train: [24][0/126], lr: 0.00003	Time 0.712 (0.712)	Data 0.664 (0.664)	Prec@1 67.188 (67.188)	Prec@1 39.844 (39.844)	Prec@1 30.469 (30.469)	Prec@5 91.406 (91.406)	Prec@5 67.188 (67.188)	Prec@5 63.281 (63.281)	Loss 3.7899 (3.7899)   loss_verb 1.1147   loss_noun 2.4977	beta 0.285, 0.285, 0.190  loss_a 1.9726	gamma 0.003000  loss_e_verb 2.4125 loss_e_noun 4.9945	
Train: [24][50/126], lr: 0.00003	Time 0.093 (0.107)	Data 0.026 (0.035)	Prec@1 69.531 (66.069)	Prec@1 34.375 (42.096)	Prec@1 28.125 (31.587)	Prec@5 90.625 (92.019)	Prec@5 72.656 (69.577)	Prec@5 67.969 (65.977)	Loss 3.8555 (3.7549)   loss_verb 1.1478   loss_noun 2.4339	beta 0.289, 0.289, 0.193  loss_a 1.9535	gamma 0.003000  loss_e_verb 2.3076 loss_e_noun 4.7170	
Train: [24][100/126], lr: 0.00003	Time 0.092 (0.098)	Data 0.023 (0.028)	Prec@1 61.719 (66.468)	Prec@1 42.969 (41.917)	Prec@1 30.469 (32.101)	Prec@5 89.844 (91.894)	Prec@5 69.531 (69.291)	Prec@5 65.625 (65.795)	Loss 3.8725 (3.7538)   loss_verb 1.1459   loss_noun 2.4330	beta 0.293, 0.293, 0.196  loss_a 1.9538	gamma 0.003000  loss_e_verb 2.3200 loss_e_noun 4.7383	
Train: [25][0/126], lr: 0.00003	Time 0.728 (0.728)	Data 0.687 (0.687)	Prec@1 64.844 (64.844)	Prec@1 47.656 (47.656)	Prec@1 36.719 (36.719)	Prec@5 92.188 (92.188)	Prec@5 69.531 (69.531)	Prec@5 65.625 (65.625)	Loss 3.6528 (3.6528)   loss_verb 1.1359   loss_noun 2.1860	beta 0.296, 0.296, 0.197  loss_a 1.9812	gamma 0.003000  loss_e_verb 2.3893 loss_e_noun 4.7174	
Train: [25][50/126], lr: 0.00003	Time 0.094 (0.107)	Data 0.029 (0.036)	Prec@1 70.312 (66.498)	Prec@1 43.750 (41.774)	Prec@1 36.719 (32.154)	Prec@5 89.844 (91.314)	Prec@5 71.094 (69.056)	Prec@5 65.625 (65.257)	Loss 3.6689 (3.7612)   loss_verb 1.1526   loss_noun 2.4359	beta 0.300, 0.300, 0.200  loss_a 1.9564	gamma 0.003000  loss_e_verb 2.3418 loss_e_noun 4.7303	
Train: [25][100/126], lr: 0.00003	Time 0.091 (0.098)	Data 0.016 (0.029)	Prec@1 64.062 (66.530)	Prec@1 39.062 (42.218)	Prec@1 30.469 (32.573)	Prec@5 89.844 (91.592)	Prec@5 67.188 (69.261)	Prec@5 62.500 (65.610)	Loss 3.8603 (3.7528)   loss_verb 1.1531   loss_noun 2.4213	beta 0.304, 0.304, 0.203  loss_a 1.9550	gamma 0.003000  loss_e_verb 2.3350 loss_e_noun 4.7319	
Train: [26][0/126], lr: 0.00003	Time 0.693 (0.693)	Data 0.644 (0.644)	Prec@1 64.062 (64.062)	Prec@1 43.750 (43.750)	Prec@1 32.812 (32.812)	Prec@5 94.531 (94.531)	Prec@5 68.750 (68.750)	Prec@5 67.969 (67.969)	Loss 3.7124 (3.7124)   loss_verb 1.0991   loss_noun 2.4025	beta 0.306, 0.306, 0.204  loss_a 1.9509	gamma 0.003000  loss_e_verb 2.2793 loss_e_noun 4.8481	
Train: [26][50/126], lr: 0.00003	Time 0.092 (0.111)	Data 0.013 (0.033)	Prec@1 60.156 (66.896)	Prec@1 37.500 (41.345)	Prec@1 25.000 (31.924)	Prec@5 90.625 (92.019)	Prec@5 64.062 (68.413)	Prec@5 60.156 (65.181)	Loss 3.9671 (3.7658)   loss_verb 1.1349   loss_noun 2.4629	beta 0.310, 0.310, 0.207  loss_a 1.9563	gamma 0.003000  loss_e_verb 2.3332 loss_e_noun 4.7547	
Train: [26][100/126], lr: 0.00003	Time 0.096 (0.100)	Data 0.030 (0.027)	Prec@1 64.844 (66.654)	Prec@1 37.500 (41.894)	Prec@1 32.031 (32.317)	Prec@5 91.406 (91.863)	Prec@5 66.406 (68.874)	Prec@5 63.281 (65.509)	Loss 3.9176 (3.7546)   loss_verb 1.1435   loss_noun 2.4335	beta 0.314, 0.314, 0.210  loss_a 1.9555	gamma 0.003000  loss_e_verb 2.3333 loss_e_noun 4.7460	
Train: [27][0/126], lr: 0.00003	Time 0.711 (0.711)	Data 0.662 (0.662)	Prec@1 66.406 (66.406)	Prec@1 41.406 (41.406)	Prec@1 28.906 (28.906)	Prec@5 91.406 (91.406)	Prec@5 73.438 (73.438)	Prec@5 71.094 (71.094)	Loss 3.5970 (3.5970)   loss_verb 1.0363   loss_noun 2.2746	beta 0.316, 0.316, 0.211  loss_a 1.9312	gamma 0.003000  loss_e_verb 2.2934 loss_e_noun 4.6222	
Train: [27][50/126], lr: 0.00003	Time 0.084 (0.107)	Data 0.016 (0.037)	Prec@1 64.844 (67.111)	Prec@1 39.844 (42.417)	Prec@1 30.469 (32.644)	Prec@5 93.750 (91.314)	Prec@5 67.969 (69.317)	Prec@5 64.062 (65.671)	Loss 3.8374 (3.7585)   loss_verb 1.1470   loss_noun 2.4362	beta 0.320, 0.320, 0.214  loss_a 1.9564	gamma 0.003000  loss_e_verb 2.3037 loss_e_noun 4.7110	
Train: [27][100/126], lr: 0.00003	Time 0.082 (0.098)	Data 0.017 (0.029)	Prec@1 60.156 (66.414)	Prec@1 39.062 (42.698)	Prec@1 28.125 (32.658)	Prec@5 92.969 (91.259)	Prec@5 66.406 (69.477)	Prec@5 64.062 (65.733)	Loss 3.8902 (3.7633)   loss_verb 1.1645   loss_noun 2.4298	beta 0.325, 0.325, 0.216  loss_a 1.9556	gamma 0.003000  loss_e_verb 2.3212 loss_e_noun 4.7287	
Train: [28][0/126], lr: 0.00003	Time 0.736 (0.736)	Data 0.682 (0.682)	Prec@1 64.062 (64.062)	Prec@1 42.188 (42.188)	Prec@1 31.250 (31.250)	Prec@5 91.406 (91.406)	Prec@5 67.188 (67.188)	Prec@5 65.625 (65.625)	Loss 3.8775 (3.8775)   loss_verb 1.2008   loss_noun 2.6126	beta 0.327, 0.327, 0.218  loss_a 1.9605	gamma 0.003000  loss_e_verb 2.2137 loss_e_noun 4.6872	
Train: [28][50/126], lr: 0.00003	Time 0.090 (0.107)	Data 0.026 (0.035)	Prec@1 65.625 (65.717)	Prec@1 33.594 (42.203)	Prec@1 25.000 (32.062)	Prec@5 93.750 (91.452)	Prec@5 67.188 (68.811)	Prec@5 64.062 (65.227)	Loss 3.8478 (3.7823)   loss_verb 1.1967   loss_noun 2.4352	beta 0.331, 0.331, 0.220  loss_a 1.9557	gamma 0.003000  loss_e_verb 2.3174 loss_e_noun 4.7313	
Train: [28][100/126], lr: 0.00003	Time 0.090 (0.098)	Data 0.021 (0.028)	Prec@1 65.625 (66.290)	Prec@1 35.938 (41.878)	Prec@1 29.688 (32.194)	Prec@5 92.969 (91.491)	Prec@5 66.406 (68.820)	Prec@5 64.062 (65.122)	Loss 3.9332 (3.7744)   loss_verb 1.1732   loss_noun 2.4429	beta 0.335, 0.335, 0.223  loss_a 1.9557	gamma 0.003000  loss_e_verb 2.3351 loss_e_noun 4.7352	
Train: [29][0/126], lr: 0.00003	Time 0.708 (0.708)	Data 0.659 (0.659)	Prec@1 74.219 (74.219)	Prec@1 37.500 (37.500)	Prec@1 30.469 (30.469)	Prec@5 93.750 (93.750)	Prec@5 71.094 (71.094)	Prec@5 67.969 (67.969)	Loss 3.7475 (3.7475)   loss_verb 0.9833   loss_noun 2.5617	beta 0.337, 0.337, 0.224  loss_a 1.9643	gamma 0.003000  loss_e_verb 2.3313 loss_e_noun 4.7971	
Train: [29][50/126], lr: 0.00003	Time 0.093 (0.116)	Data 0.023 (0.045)	Prec@1 61.719 (66.958)	Prec@1 34.375 (41.973)	Prec@1 26.562 (32.230)	Prec@5 91.406 (91.759)	Prec@5 65.625 (68.964)	Prec@5 62.500 (65.380)	Loss 3.9384 (3.7565)   loss_verb 1.1417   loss_noun 2.4357	beta 0.341, 0.341, 0.227  loss_a 1.9572	gamma 0.003000  loss_e_verb 2.3106 loss_e_noun 4.7190	
Train: [29][100/126], lr: 0.00003	Time 0.089 (0.103)	Data 0.022 (0.033)	Prec@1 73.438 (66.847)	Prec@1 41.406 (42.396)	Prec@1 32.812 (32.410)	Prec@5 91.406 (91.739)	Prec@5 70.312 (69.469)	Prec@5 64.062 (65.873)	Loss 3.7390 (3.7478)   loss_verb 1.1451   loss_noun 2.4190	beta 0.345, 0.345, 0.230  loss_a 1.9553	gamma 0.003000  loss_e_verb 2.3107 loss_e_noun 4.7219	
Train: [30][0/126], lr: 0.00003	Time 0.681 (0.681)	Data 0.641 (0.641)	Prec@1 67.969 (67.969)	Prec@1 43.750 (43.750)	Prec@1 34.375 (34.375)	Prec@5 90.625 (90.625)	Prec@5 67.969 (67.969)	Prec@5 63.281 (63.281)	Loss 3.7340 (3.7340)   loss_verb 1.1572   loss_noun 2.4295	beta 0.347, 0.347, 0.231  loss_a 1.9304	gamma 0.003000  loss_e_verb 2.1995 loss_e_noun 4.6386	
Train: [30][50/126], lr: 0.00003	Time 0.089 (0.106)	Data 0.024 (0.034)	Prec@1 67.188 (66.774)	Prec@1 45.312 (42.264)	Prec@1 36.719 (32.475)	Prec@5 94.531 (91.881)	Prec@5 66.406 (69.225)	Prec@5 63.281 (65.702)	Loss 3.7417 (3.7507)   loss_verb 1.1529   loss_noun 2.4213	beta 0.350, 0.350, 0.234  loss_a 1.9531	gamma 0.003000  loss_e_verb 2.3237 loss_e_noun 4.7302	
Train: [30][100/126], lr: 0.00003	Time 0.083 (0.098)	Data 0.018 (0.028)	Prec@1 62.500 (66.801)	Prec@1 41.406 (42.164)	Prec@1 31.250 (32.178)	Prec@5 89.062 (91.739)	Prec@5 60.938 (68.905)	Prec@5 56.250 (65.354)	Loss 3.8749 (3.7611)   loss_verb 1.1565   loss_noun 2.4314	beta 0.354, 0.354, 0.236  loss_a 1.9566	gamma 0.003000  loss_e_verb 2.3341 loss_e_noun 4.7370	
total training time: 355.70670080184937
checkpoint
testing on the test set
preparing the model......
Multi-Scale Temporal Relation Network Module in use ['5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']
loading data......
  0%|          | 0/16 [00:00<?, ?it/s]/home/ac1xliu/experiments/DAAR/epicuda/EPIC-KITCHENS-100_UDA_TA3N/models.py:477: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  base_out = (self.softmax(base_out[0]), self.softmax(base_out[1]))
Testing Results: Prec@1 verb 44.245  Prec@1 noun 20.390 Prec@1 action 13.711 Prec@5 verb 76.119 Prec@5 noun 40.412 Prec@5 action 35.403 Loss 4.92807
