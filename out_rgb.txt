(128, 207)
exp_path: model/action-model/Testexp-SGD-share_params_Y-lr_3e-3-bS_128_207/epic-5seg-disDA_none-alpha_0-advDA_RevGrad-beta_0.75_0.75_0.5-useBN_none-addlossDA_attentive_entropy-gamma_0.003-ensDA_none-mu_0-useAttn_TransAttn-n_attn_1/
RGB
Baseline: video
Frame aggregation method: trn-m
target data usage: uSv
Apply the adversarial-based Domain Adaptation approach: RevGrad
preparing the model......
Multi-Scale Temporal Relation Network Module in use ['5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']
using SGD
checking the checkpoint......
loading data......
start training......
Train: [1][0/126], lr: 0.00300	Time 1.440 (1.440)	Data 0.659 (0.659)	Prec@1 0.781 (0.781)	Prec@1 0.000 (0.000)	Prec@1 0.000 (0.000)	Prec@5 2.344 (2.344)	Prec@5 0.781 (0.781)	Prec@5 0.000 (0.000)	Loss 7.2458 (7.2458)   loss_verb 4.5754   loss_noun 5.7046	beta 0.012, 0.012, 0.008  loss_a 2.0797	gamma 0.003000  loss_e_verb 7.7456 loss_e_noun 9.6573	
Train: [1][50/126], lr: 0.00300	Time 0.087 (0.115)	Data 0.021 (0.030)	Prec@1 32.812 (21.477)	Prec@1 14.062 (6.740)	Prec@1 3.906 (1.455)	Prec@5 75.000 (64.629)	Prec@5 36.719 (21.032)	Prec@5 33.594 (15.349)	Loss 5.3077 (6.0005)   loss_verb 3.0814   loss_noun 4.7811	beta 0.017, 0.017, 0.012  loss_a 2.0485	gamma 0.003000  loss_e_verb 5.3618 loss_e_noun 8.4186	
Train: [1][100/126], lr: 0.00300	Time 0.083 (0.102)	Data 0.017 (0.024)	Prec@1 41.406 (28.976)	Prec@1 20.312 (12.577)	Prec@1 9.375 (4.471)	Prec@5 84.375 (71.542)	Prec@5 48.438 (30.384)	Prec@5 43.750 (25.116)	Loss 4.8203 (5.5529)   loss_verb 2.6634   loss_noun 4.3341	beta 0.022, 0.022, 0.015  loss_a 2.0352	gamma 0.003000  loss_e_verb 4.7756 loss_e_noun 7.8876	
Train: [2][0/126], lr: 0.00300	Time 0.667 (0.667)	Data 0.631 (0.631)	Prec@1 38.281 (38.281)	Prec@1 25.000 (25.000)	Prec@1 10.156 (10.156)	Prec@5 78.906 (78.906)	Prec@5 54.688 (54.688)	Prec@5 48.438 (48.438)	Loss 4.7167 (4.7167)   loss_verb 2.0504   loss_noun 3.3209	beta 0.025, 0.025, 0.017  loss_a 2.0157	gamma 0.003000  loss_e_verb 3.7112 loss_e_noun 6.5053	
Train: [2][50/126], lr: 0.00300	Time 0.083 (0.105)	Data 0.017 (0.033)	Prec@1 37.500 (40.901)	Prec@1 34.375 (29.442)	Prec@1 17.188 (14.308)	Prec@5 85.156 (83.548)	Prec@5 64.062 (56.756)	Prec@5 57.031 (50.368)	Loss 4.5182 (4.5658)   loss_verb 1.9890   loss_noun 3.1368	beta 0.030, 0.030, 0.020  loss_a 1.9876	gamma 0.003000  loss_e_verb 3.7846 loss_e_noun 6.4300	
Train: [2][100/126], lr: 0.00300	Time 0.082 (0.097)	Data 0.019 (0.027)	Prec@1 47.656 (41.654)	Prec@1 37.500 (31.637)	Prec@1 22.656 (15.610)	Prec@5 87.500 (83.663)	Prec@5 67.188 (59.321)	Prec@5 64.062 (52.522)	Loss 4.2072 (4.4869)   loss_verb 1.9701   loss_noun 3.0314	beta 0.035, 0.035, 0.023  loss_a 1.9712	gamma 0.003000  loss_e_verb 3.7222 loss_e_noun 6.2411	
Train: [3][0/126], lr: 0.00300	Time 0.700 (0.700)	Data 0.665 (0.665)	Prec@1 39.062 (39.062)	Prec@1 37.500 (37.500)	Prec@1 23.438 (23.438)	Prec@5 82.031 (82.031)	Prec@5 65.625 (65.625)	Prec@5 59.375 (59.375)	Loss 4.2521 (4.2521)   loss_verb 1.9769   loss_noun 2.6015	beta 0.037, 0.037, 0.025  loss_a 1.9492	gamma 0.003000  loss_e_verb 3.4527 loss_e_noun 5.6729	
Train: [3][50/126], lr: 0.00300	Time 0.085 (0.107)	Data 0.017 (0.034)	Prec@1 45.312 (45.833)	Prec@1 38.281 (39.782)	Prec@1 20.312 (21.339)	Prec@5 86.719 (85.846)	Prec@5 68.750 (68.704)	Prec@5 62.500 (61.458)	Loss 4.1313 (4.1416)   loss_verb 1.7942   loss_noun 2.5901	beta 0.042, 0.042, 0.028  loss_a 1.9362	gamma 0.003000  loss_e_verb 3.3297 loss_e_noun 5.5418	
Train: [3][100/126], lr: 0.00300	Time 0.086 (0.098)	Data 0.021 (0.027)	Prec@1 55.469 (45.661)	Prec@1 46.875 (40.130)	Prec@1 29.688 (21.511)	Prec@5 89.844 (86.417)	Prec@5 75.781 (69.191)	Prec@5 71.094 (62.167)	Loss 3.7577 (4.1038)   loss_verb 1.7790   loss_noun 2.5552	beta 0.047, 0.047, 0.032  loss_a 1.9235	gamma 0.003000  loss_e_verb 3.3397 loss_e_noun 5.5083	
Train: [4][0/126], lr: 0.00300	Time 0.662 (0.662)	Data 0.625 (0.625)	Prec@1 46.094 (46.094)	Prec@1 52.344 (52.344)	Prec@1 25.781 (25.781)	Prec@5 86.719 (86.719)	Prec@5 78.906 (78.906)	Prec@5 71.875 (71.875)	Loss 3.7941 (3.7941)   loss_verb 1.7006   loss_noun 2.1394	beta 0.050, 0.050, 0.033  loss_a 1.8613	gamma 0.003000  loss_e_verb 3.2283 loss_e_noun 5.2916	
Train: [4][50/126], lr: 0.00300	Time 0.093 (0.106)	Data 0.020 (0.034)	Prec@1 51.562 (48.146)	Prec@1 48.438 (45.787)	Prec@1 32.031 (25.475)	Prec@5 89.062 (88.388)	Prec@5 74.219 (74.433)	Prec@5 68.750 (67.892)	Loss 3.7153 (3.8372)   loss_verb 1.6504   loss_noun 2.2484	beta 0.055, 0.055, 0.037  loss_a 1.8752	gamma 0.003000  loss_e_verb 3.2353 loss_e_noun 5.1588	
Train: [4][100/126], lr: 0.00300	Time 0.083 (0.098)	Data 0.018 (0.027)	Prec@1 48.438 (48.066)	Prec@1 43.750 (44.933)	Prec@1 25.000 (25.124)	Prec@5 89.062 (88.521)	Prec@5 75.781 (74.381)	Prec@5 69.531 (67.860)	Loss 3.8743 (3.8507)   loss_verb 1.6580   loss_noun 2.2711	beta 0.060, 0.060, 0.040  loss_a 1.8737	gamma 0.003000  loss_e_verb 3.2009 loss_e_noun 5.1181	
Train: [5][0/126], lr: 0.00300	Time 0.694 (0.694)	Data 0.659 (0.659)	Prec@1 45.312 (45.312)	Prec@1 52.344 (52.344)	Prec@1 25.781 (25.781)	Prec@5 85.938 (85.938)	Prec@5 75.781 (75.781)	Prec@5 67.188 (67.188)	Loss 3.7168 (3.7168)   loss_verb 1.6779   loss_noun 1.9828	beta 0.062, 0.062, 0.042  loss_a 1.8742	gamma 0.003000  loss_e_verb 3.2774 loss_e_noun 4.8975	
Train: [5][50/126], lr: 0.00300	Time 0.086 (0.107)	Data 0.022 (0.034)	Prec@1 48.438 (50.751)	Prec@1 51.562 (49.173)	Prec@1 26.562 (28.738)	Prec@5 93.750 (89.706)	Prec@5 82.812 (77.374)	Prec@5 77.344 (71.232)	Loss 3.5764 (3.7136)   loss_verb 1.5729   loss_noun 2.0941	beta 0.067, 0.067, 0.045  loss_a 1.8682	gamma 0.003000  loss_e_verb 3.0514 loss_e_noun 4.8672	
Train: [5][100/126], lr: 0.00300	Time 0.092 (0.099)	Data 0.023 (0.028)	Prec@1 53.906 (50.031)	Prec@1 51.562 (48.128)	Prec@1 32.031 (27.839)	Prec@5 89.062 (89.681)	Prec@5 80.469 (77.290)	Prec@5 73.438 (71.040)	Loss 3.7105 (3.7292)   loss_verb 1.5800   loss_noun 2.1043	beta 0.072, 0.072, 0.048  loss_a 1.8752	gamma 0.003000  loss_e_verb 3.0441 loss_e_noun 4.8425	
Train: [6][0/126], lr: 0.00300	Time 0.722 (0.722)	Data 0.679 (0.679)	Prec@1 50.781 (50.781)	Prec@1 46.875 (46.875)	Prec@1 25.781 (25.781)	Prec@5 90.625 (90.625)	Prec@5 85.156 (85.156)	Prec@5 77.344 (77.344)	Loss 3.6739 (3.6739)   loss_verb 1.5451   loss_noun 2.0172	beta 0.075, 0.075, 0.050  loss_a 1.8806	gamma 0.003000  loss_e_verb 3.1170 loss_e_noun 4.9821	
Train: [6][50/126], lr: 0.00300	Time 0.091 (0.109)	Data 0.027 (0.033)	Prec@1 55.469 (52.635)	Prec@1 53.125 (51.210)	Prec@1 33.594 (30.070)	Prec@5 92.188 (91.544)	Prec@5 84.375 (80.453)	Prec@5 79.688 (75.046)	Loss 3.4497 (3.5898)   loss_verb 1.4490   loss_noun 1.9433	beta 0.080, 0.080, 0.053  loss_a 1.8826	gamma 0.003000  loss_e_verb 2.8135 loss_e_noun 4.5101	
Train: [6][100/126], lr: 0.00300	Time 0.084 (0.099)	Data 0.017 (0.027)	Prec@1 46.094 (52.630)	Prec@1 51.562 (51.013)	Prec@1 25.000 (30.422)	Prec@5 91.406 (90.749)	Prec@5 74.219 (79.742)	Prec@5 69.531 (73.963)	Loss 3.6979 (3.6108)   loss_verb 1.4836   loss_noun 1.9592	beta 0.085, 0.085, 0.056  loss_a 1.8785	gamma 0.003000  loss_e_verb 2.8040 loss_e_noun 4.4818	
Train: [7][0/126], lr: 0.00300	Time 0.673 (0.673)	Data 0.635 (0.635)	Prec@1 49.219 (49.219)	Prec@1 52.344 (52.344)	Prec@1 30.469 (30.469)	Prec@5 93.750 (93.750)	Prec@5 80.469 (80.469)	Prec@5 76.562 (76.562)	Loss 3.6340 (3.6340)   loss_verb 1.5695   loss_noun 1.8956	beta 0.087, 0.087, 0.058  loss_a 1.8904	gamma 0.003000  loss_e_verb 2.8437 loss_e_noun 4.5445	
Train: [7][50/126], lr: 0.00300	Time 0.086 (0.106)	Data 0.020 (0.035)	Prec@1 57.812 (53.447)	Prec@1 59.375 (52.926)	Prec@1 36.719 (32.506)	Prec@5 90.625 (90.962)	Prec@5 82.031 (81.924)	Prec@5 77.344 (75.980)	Loss 3.2820 (3.5257)   loss_verb 1.4568   loss_noun 1.8596	beta 0.092, 0.092, 0.061  loss_a 1.8569	gamma 0.003000  loss_e_verb 2.7194 loss_e_noun 4.3246	
Train: [7][100/126], lr: 0.00300	Time 0.089 (0.098)	Data 0.015 (0.028)	Prec@1 49.219 (53.690)	Prec@1 51.562 (53.110)	Prec@1 27.344 (32.557)	Prec@5 91.406 (91.190)	Prec@5 78.125 (81.761)	Prec@5 74.219 (76.052)	Loss 3.6293 (3.5250)   loss_verb 1.4514   loss_noun 1.8618	beta 0.097, 0.097, 0.065  loss_a 1.8580	gamma 0.003000  loss_e_verb 2.6787 loss_e_noun 4.2593	
Train: [8][0/126], lr: 0.00300	Time 0.712 (0.712)	Data 0.671 (0.671)	Prec@1 56.250 (56.250)	Prec@1 67.188 (67.188)	Prec@1 41.406 (41.406)	Prec@5 92.969 (92.969)	Prec@5 83.594 (83.594)	Prec@5 78.125 (78.125)	Loss 3.3451 (3.3451)   loss_verb 1.3208   loss_noun 1.6897	beta 0.099, 0.099, 0.066  loss_a 1.8294	gamma 0.003000  loss_e_verb 2.7327 loss_e_noun 4.1949	
Train: [8][50/126], lr: 0.00300	Time 0.086 (0.109)	Data 0.017 (0.034)	Prec@1 53.125 (55.714)	Prec@1 60.156 (54.994)	Prec@1 35.156 (34.727)	Prec@5 96.094 (92.188)	Prec@5 85.156 (83.012)	Prec@5 82.812 (77.880)	Loss 3.4060 (3.4312)   loss_verb 1.3679   loss_noun 1.7576	beta 0.104, 0.104, 0.070  loss_a 1.8586	gamma 0.003000  loss_e_verb 2.5438 loss_e_noun 4.0057	
Train: [8][100/126], lr: 0.00300	Time 0.087 (0.099)	Data 0.014 (0.027)	Prec@1 60.156 (55.608)	Prec@1 55.469 (54.703)	Prec@1 37.500 (34.282)	Prec@5 91.406 (91.878)	Prec@5 82.812 (82.635)	Prec@5 77.344 (77.437)	Loss 3.5156 (3.4519)   loss_verb 1.3832   loss_noun 1.7751	beta 0.109, 0.109, 0.073  loss_a 1.8629	gamma 0.003000  loss_e_verb 2.5509 loss_e_noun 4.0246	
Train: [9][0/126], lr: 0.00300	Time 0.704 (0.704)	Data 0.666 (0.666)	Prec@1 57.031 (57.031)	Prec@1 60.938 (60.938)	Prec@1 33.594 (33.594)	Prec@5 95.312 (95.312)	Prec@5 84.375 (84.375)	Prec@5 80.469 (80.469)	Loss 3.2834 (3.2834)   loss_verb 1.2440   loss_noun 1.5749	beta 0.112, 0.112, 0.074  loss_a 1.8643	gamma 0.003000  loss_e_verb 2.5150 loss_e_noun 3.9749	
Train: [9][50/126], lr: 0.00300	Time 0.088 (0.109)	Data 0.017 (0.032)	Prec@1 55.469 (56.173)	Prec@1 52.344 (56.526)	Prec@1 31.250 (34.743)	Prec@5 93.750 (93.030)	Prec@5 82.031 (84.421)	Prec@5 77.344 (79.565)	Loss 3.4567 (3.3736)   loss_verb 1.3270   loss_noun 1.6697	beta 0.117, 0.117, 0.078  loss_a 1.8659	gamma 0.003000  loss_e_verb 2.4461 loss_e_noun 3.8244	
Train: [9][100/126], lr: 0.00300	Time 0.089 (0.099)	Data 0.028 (0.026)	Prec@1 57.812 (56.590)	Prec@1 48.438 (56.637)	Prec@1 31.250 (35.628)	Prec@5 93.750 (92.868)	Prec@5 79.688 (84.360)	Prec@5 78.125 (79.595)	Loss 3.4960 (3.3788)   loss_verb 1.3303   loss_noun 1.6842	beta 0.121, 0.121, 0.081  loss_a 1.8622	gamma 0.003000  loss_e_verb 2.4266 loss_e_noun 3.7881	
Train: [10][0/126], lr: 0.00030	Time 0.702 (0.702)	Data 0.670 (0.670)	Prec@1 54.688 (54.688)	Prec@1 63.281 (63.281)	Prec@1 38.281 (38.281)	Prec@5 92.969 (92.969)	Prec@5 89.062 (89.062)	Prec@5 85.938 (85.938)	Loss 3.1964 (3.1964)   loss_verb 1.2838   loss_noun 1.3531	beta 0.124, 0.124, 0.083  loss_a 1.8691	gamma 0.003000  loss_e_verb 2.3165 loss_e_noun 3.5344	
Train: [10][50/126], lr: 0.00030	Time 0.095 (0.111)	Data 0.016 (0.033)	Prec@1 55.469 (58.226)	Prec@1 64.844 (59.161)	Prec@1 36.719 (38.266)	Prec@5 90.625 (93.244)	Prec@5 88.281 (86.780)	Prec@5 80.469 (81.664)	Loss 3.3037 (3.2633)   loss_verb 1.2518   loss_noun 1.5503	beta 0.129, 0.129, 0.086  loss_a 1.8531	gamma 0.003000  loss_e_verb 2.3679 loss_e_noun 3.7372	
Train: [10][100/126], lr: 0.00030	Time 0.086 (0.101)	Data 0.012 (0.026)	Prec@1 55.469 (60.272)	Prec@1 56.250 (59.584)	Prec@1 34.375 (39.558)	Prec@5 96.094 (93.773)	Prec@5 78.906 (86.471)	Prec@5 76.562 (82.047)	Loss 3.3902 (3.2332)   loss_verb 1.2118   loss_noun 1.5383	beta 0.133, 0.133, 0.089  loss_a 1.8491	gamma 0.003000  loss_e_verb 2.3299 loss_e_noun 3.6772	
Train: [11][0/126], lr: 0.00030	Time 0.704 (0.704)	Data 0.652 (0.652)	Prec@1 64.062 (64.062)	Prec@1 61.719 (61.719)	Prec@1 41.406 (41.406)	Prec@5 92.188 (92.188)	Prec@5 91.406 (91.406)	Prec@5 83.594 (83.594)	Loss 3.1832 (3.1832)   loss_verb 1.1798   loss_noun 1.4338	beta 0.136, 0.136, 0.091  loss_a 1.8679	gamma 0.003000  loss_e_verb 2.2604 loss_e_noun 3.3737	
Train: [11][50/126], lr: 0.00030	Time 0.091 (0.109)	Data 0.018 (0.033)	Prec@1 69.531 (61.382)	Prec@1 55.469 (61.428)	Prec@1 43.750 (41.360)	Prec@5 98.438 (94.210)	Prec@5 86.719 (87.286)	Prec@5 85.156 (83.165)	Loss 3.0740 (3.1913)   loss_verb 1.1785   loss_noun 1.4826	beta 0.141, 0.141, 0.094  loss_a 1.8520	gamma 0.003000  loss_e_verb 2.2570 loss_e_noun 3.5405	
Train: [11][100/126], lr: 0.00030	Time 0.097 (0.099)	Data 0.030 (0.027)	Prec@1 65.625 (61.618)	Prec@1 66.406 (61.587)	Prec@1 49.219 (41.383)	Prec@5 92.969 (94.322)	Prec@5 89.062 (87.268)	Prec@5 83.594 (83.238)	Loss 3.0080 (3.1750)   loss_verb 1.1679   loss_noun 1.4695	beta 0.146, 0.146, 0.097  loss_a 1.8477	gamma 0.003000  loss_e_verb 2.2480 loss_e_noun 3.5124	
Train: [12][0/126], lr: 0.00030	Time 0.686 (0.686)	Data 0.657 (0.657)	Prec@1 57.812 (57.812)	Prec@1 60.156 (60.156)	Prec@1 33.594 (33.594)	Prec@5 94.531 (94.531)	Prec@5 90.625 (90.625)	Prec@5 85.938 (85.938)	Loss 3.1553 (3.1553)   loss_verb 1.1940   loss_noun 1.4191	beta 0.148, 0.148, 0.099  loss_a 1.8399	gamma 0.003000  loss_e_verb 2.3384 loss_e_noun 3.5555	
Train: [12][50/126], lr: 0.00030	Time 0.089 (0.106)	Data 0.021 (0.036)	Prec@1 62.500 (62.347)	Prec@1 62.500 (62.102)	Prec@1 46.094 (42.371)	Prec@5 94.531 (94.133)	Prec@5 86.719 (87.086)	Prec@5 81.250 (82.782)	Loss 3.2000 (3.1616)   loss_verb 1.1549   loss_noun 1.4544	beta 0.153, 0.153, 0.102  loss_a 1.8483	gamma 0.003000  loss_e_verb 2.2502 loss_e_noun 3.5062	
Train: [12][100/126], lr: 0.00030	Time 0.089 (0.098)	Data 0.021 (0.028)	Prec@1 59.375 (62.686)	Prec@1 49.219 (62.214)	Prec@1 35.156 (42.412)	Prec@5 89.844 (94.261)	Prec@5 83.594 (87.570)	Prec@5 76.562 (83.408)	Loss 3.5239 (3.1492)   loss_verb 1.1463   loss_noun 1.4408	beta 0.158, 0.158, 0.105  loss_a 1.8472	gamma 0.003000  loss_e_verb 2.2347 loss_e_noun 3.4661	
Train: [13][0/126], lr: 0.00030	Time 0.707 (0.707)	Data 0.666 (0.666)	Prec@1 70.312 (70.312)	Prec@1 61.719 (61.719)	Prec@1 44.531 (44.531)	Prec@5 94.531 (94.531)	Prec@5 90.625 (90.625)	Prec@5 85.938 (85.938)	Loss 3.0987 (3.0987)   loss_verb 1.0951   loss_noun 1.4286	beta 0.160, 0.160, 0.107  loss_a 1.8286	gamma 0.003000  loss_e_verb 2.1378 loss_e_noun 3.3327	
Train: [13][50/126], lr: 0.00030	Time 0.088 (0.108)	Data 0.018 (0.035)	Prec@1 64.844 (61.994)	Prec@1 64.844 (61.749)	Prec@1 46.875 (41.881)	Prec@5 93.750 (94.164)	Prec@5 85.938 (87.485)	Prec@5 82.031 (83.303)	Loss 3.1720 (3.1632)   loss_verb 1.1574   loss_noun 1.4558	beta 0.165, 0.165, 0.110  loss_a 1.8481	gamma 0.003000  loss_e_verb 2.2182 loss_e_noun 3.4378	
Train: [13][100/126], lr: 0.00030	Time 0.094 (0.099)	Data 0.023 (0.028)	Prec@1 66.406 (62.631)	Prec@1 64.844 (61.959)	Prec@1 45.312 (42.342)	Prec@5 93.750 (94.477)	Prec@5 90.625 (87.593)	Prec@5 86.719 (83.733)	Loss 3.0158 (3.1497)   loss_verb 1.1378   loss_noun 1.4457	beta 0.169, 0.169, 0.113  loss_a 1.8495	gamma 0.003000  loss_e_verb 2.2001 loss_e_noun 3.4203	
Train: [14][0/126], lr: 0.00030	Time 0.697 (0.697)	Data 0.658 (0.658)	Prec@1 67.969 (67.969)	Prec@1 67.188 (67.188)	Prec@1 47.656 (47.656)	Prec@5 96.875 (96.875)	Prec@5 86.719 (86.719)	Prec@5 83.594 (83.594)	Loss 3.0733 (3.0733)   loss_verb 1.0725   loss_noun 1.3029	beta 0.172, 0.172, 0.115  loss_a 1.8770	gamma 0.003000  loss_e_verb 2.2467 loss_e_noun 3.4573	
Train: [14][50/126], lr: 0.00030	Time 0.085 (0.107)	Data 0.013 (0.034)	Prec@1 62.500 (64.154)	Prec@1 57.812 (62.347)	Prec@1 39.844 (43.520)	Prec@5 95.312 (94.761)	Prec@5 89.062 (87.883)	Prec@5 86.719 (83.977)	Loss 3.1809 (3.1280)   loss_verb 1.1006   loss_noun 1.4284	beta 0.177, 0.177, 0.118  loss_a 1.8552	gamma 0.003000  loss_e_verb 2.1779 loss_e_noun 3.3720	
Train: [14][100/126], lr: 0.00030	Time 0.091 (0.098)	Data 0.024 (0.027)	Prec@1 64.844 (63.614)	Prec@1 63.281 (62.539)	Prec@1 50.000 (43.317)	Prec@5 92.969 (94.562)	Prec@5 89.062 (87.670)	Prec@5 83.594 (83.710)	Loss 3.2458 (3.1345)   loss_verb 1.1172   loss_noun 1.4263	beta 0.181, 0.181, 0.121  loss_a 1.8544	gamma 0.003000  loss_e_verb 2.1710 loss_e_noun 3.3643	
Train: [15][0/126], lr: 0.00030	Time 0.704 (0.704)	Data 0.666 (0.666)	Prec@1 71.875 (71.875)	Prec@1 60.156 (60.156)	Prec@1 44.531 (44.531)	Prec@5 91.406 (91.406)	Prec@5 82.812 (82.812)	Prec@5 78.906 (78.906)	Loss 3.2638 (3.2638)   loss_verb 1.0720   loss_noun 1.6516	beta 0.184, 0.184, 0.122  loss_a 1.8935	gamma 0.003000  loss_e_verb 2.1699 loss_e_noun 3.5537	
Train: [15][50/126], lr: 0.00030	Time 0.093 (0.106)	Data 0.026 (0.034)	Prec@1 70.312 (64.384)	Prec@1 66.406 (62.178)	Prec@1 53.906 (43.551)	Prec@5 92.188 (94.654)	Prec@5 90.625 (87.684)	Prec@5 83.594 (83.762)	Loss 3.0184 (3.1167)   loss_verb 1.0959   loss_noun 1.4023	beta 0.188, 0.188, 0.126  loss_a 1.8594	gamma 0.003000  loss_e_verb 2.1412 loss_e_noun 3.3450	
Train: [15][100/126], lr: 0.00030	Time 0.099 (0.098)	Data 0.025 (0.028)	Prec@1 55.469 (63.769)	Prec@1 58.594 (62.531)	Prec@1 37.500 (43.348)	Prec@5 94.531 (94.794)	Prec@5 85.938 (87.763)	Prec@5 82.812 (84.042)	Loss 3.2741 (3.1248)   loss_verb 1.1030   loss_noun 1.4101	beta 0.193, 0.193, 0.129  loss_a 1.8601	gamma 0.003000  loss_e_verb 2.1343 loss_e_noun 3.3383	
Train: [16][0/126], lr: 0.00030	Time 0.685 (0.685)	Data 0.652 (0.652)	Prec@1 68.750 (68.750)	Prec@1 70.312 (70.312)	Prec@1 52.344 (52.344)	Prec@5 98.438 (98.438)	Prec@5 86.719 (86.719)	Prec@5 85.156 (85.156)	Loss 2.9864 (2.9864)   loss_verb 0.9125   loss_noun 1.2723	beta 0.195, 0.195, 0.130  loss_a 1.8858	gamma 0.003000  loss_e_verb 2.1409 loss_e_noun 3.3661	
Train: [16][50/126], lr: 0.00030	Time 0.087 (0.105)	Data 0.023 (0.034)	Prec@1 61.719 (63.879)	Prec@1 68.750 (63.680)	Prec@1 46.875 (43.842)	Prec@5 92.188 (94.623)	Prec@5 84.375 (88.266)	Prec@5 78.125 (84.436)	Loss 3.1151 (3.0955)   loss_verb 1.0924   loss_noun 1.3678	beta 0.200, 0.200, 0.133  loss_a 1.8572	gamma 0.003000  loss_e_verb 2.1533 loss_e_noun 3.2997	
Train: [16][100/126], lr: 0.00030	Time 0.092 (0.098)	Data 0.026 (0.028)	Prec@1 60.156 (63.591)	Prec@1 67.188 (62.918)	Prec@1 43.750 (43.178)	Prec@5 95.312 (94.609)	Prec@5 89.844 (88.157)	Prec@5 87.500 (84.313)	Loss 2.9746 (3.1197)   loss_verb 1.1066   loss_noun 1.3930	beta 0.205, 0.205, 0.136  loss_a 1.8617	gamma 0.003000  loss_e_verb 2.1549 loss_e_noun 3.3123	
Train: [17][0/126], lr: 0.00030	Time 0.689 (0.689)	Data 0.650 (0.650)	Prec@1 67.969 (67.969)	Prec@1 63.281 (63.281)	Prec@1 45.312 (45.312)	Prec@5 96.094 (96.094)	Prec@5 85.156 (85.156)	Prec@5 82.031 (82.031)	Loss 2.9993 (2.9993)   loss_verb 0.9750   loss_noun 1.3499	beta 0.207, 0.207, 0.138  loss_a 1.8284	gamma 0.003000  loss_e_verb 2.1609 loss_e_noun 3.4803	
Train: [17][50/126], lr: 0.00030	Time 0.081 (0.106)	Data 0.017 (0.035)	Prec@1 67.188 (63.634)	Prec@1 67.188 (63.419)	Prec@1 47.656 (43.428)	Prec@5 97.656 (94.960)	Prec@5 88.281 (88.465)	Prec@5 86.719 (84.881)	Loss 2.9250 (3.1037)   loss_verb 1.0961   loss_noun 1.3618	beta 0.212, 0.212, 0.141  loss_a 1.8666	gamma 0.003000  loss_e_verb 2.1257 loss_e_noun 3.2490	
Train: [17][100/126], lr: 0.00030	Time 0.085 (0.098)	Data 0.025 (0.028)	Prec@1 63.281 (63.761)	Prec@1 58.594 (62.995)	Prec@1 40.625 (43.402)	Prec@5 94.531 (94.926)	Prec@5 89.844 (88.390)	Prec@5 85.938 (84.708)	Loss 3.1594 (3.1104)   loss_verb 1.0856   loss_noun 1.3783	beta 0.216, 0.216, 0.144  loss_a 1.8704	gamma 0.003000  loss_e_verb 2.1225 loss_e_noun 3.2551	
Train: [18][0/126], lr: 0.00030	Time 0.688 (0.688)	Data 0.655 (0.655)	Prec@1 61.719 (61.719)	Prec@1 57.812 (57.812)	Prec@1 40.625 (40.625)	Prec@5 94.531 (94.531)	Prec@5 86.719 (86.719)	Prec@5 82.031 (82.031)	Loss 3.1820 (3.1820)   loss_verb 1.0442   loss_noun 1.4402	beta 0.218, 0.218, 0.146  loss_a 1.9318	gamma 0.003000  loss_e_verb 2.1006 loss_e_noun 3.2452	
Train: [18][50/126], lr: 0.00030	Time 0.090 (0.106)	Data 0.016 (0.034)	Prec@1 63.281 (63.695)	Prec@1 60.938 (63.051)	Prec@1 42.969 (44.240)	Prec@5 95.312 (94.960)	Prec@5 82.031 (88.388)	Prec@5 79.688 (84.666)	Loss 3.2962 (3.1272)   loss_verb 1.0969   loss_noun 1.3947	beta 0.223, 0.223, 0.149  loss_a 1.8734	gamma 0.003000  loss_e_verb 2.1239 loss_e_noun 3.2252	
Train: [18][100/126], lr: 0.00030	Time 0.096 (0.098)	Data 0.022 (0.027)	Prec@1 67.188 (63.993)	Prec@1 64.062 (63.769)	Prec@1 49.219 (44.554)	Prec@5 96.094 (94.941)	Prec@5 93.750 (88.753)	Prec@5 90.625 (85.002)	Loss 3.0358 (3.1107)   loss_verb 1.0908   loss_noun 1.3671	beta 0.228, 0.228, 0.152  loss_a 1.8737	gamma 0.003000  loss_e_verb 2.1111 loss_e_noun 3.2229	
Train: [19][0/126], lr: 0.00030	Time 0.695 (0.695)	Data 0.662 (0.662)	Prec@1 62.500 (62.500)	Prec@1 75.000 (75.000)	Prec@1 50.781 (50.781)	Prec@5 95.312 (95.312)	Prec@5 93.750 (93.750)	Prec@5 90.625 (90.625)	Loss 2.8664 (2.8664)   loss_verb 1.0839   loss_noun 1.0130	beta 0.230, 0.230, 0.153  loss_a 1.8101	gamma 0.003000  loss_e_verb 2.0604 loss_e_noun 3.1844	
Train: [19][50/126], lr: 0.00030	Time 0.090 (0.106)	Data 0.021 (0.035)	Prec@1 66.406 (63.817)	Prec@1 55.469 (64.491)	Prec@1 38.281 (44.991)	Prec@5 93.750 (95.037)	Prec@5 90.625 (88.143)	Prec@5 84.375 (84.544)	Loss 3.1745 (3.1093)   loss_verb 1.0876   loss_noun 1.3605	beta 0.234, 0.234, 0.156  loss_a 1.8773	gamma 0.003000  loss_e_verb 2.0961 loss_e_noun 3.2072	
Train: [19][100/126], lr: 0.00030	Time 0.093 (0.098)	Data 0.019 (0.028)	Prec@1 60.156 (63.428)	Prec@1 59.375 (64.503)	Prec@1 39.844 (44.562)	Prec@5 97.656 (94.802)	Prec@5 86.719 (88.629)	Prec@5 85.156 (84.793)	Loss 3.1999 (3.1091)   loss_verb 1.0951   loss_noun 1.3525	beta 0.239, 0.239, 0.159  loss_a 1.8774	gamma 0.003000  loss_e_verb 2.0844 loss_e_noun 3.1993	
Train: [20][0/126], lr: 0.00003	Time 0.699 (0.699)	Data 0.656 (0.656)	Prec@1 66.406 (66.406)	Prec@1 71.094 (71.094)	Prec@1 50.781 (50.781)	Prec@5 93.750 (93.750)	Prec@5 91.406 (91.406)	Prec@5 85.938 (85.938)	Loss 3.0547 (3.0547)   loss_verb 1.1905   loss_noun 1.1186	beta 0.241, 0.241, 0.161  loss_a 1.8922	gamma 0.003000  loss_e_verb 2.1086 loss_e_noun 3.1717	
Train: [20][50/126], lr: 0.00003	Time 0.092 (0.106)	Data 0.023 (0.035)	Prec@1 62.500 (65.012)	Prec@1 64.844 (64.062)	Prec@1 43.750 (44.730)	Prec@5 93.750 (94.991)	Prec@5 91.406 (88.603)	Prec@5 86.719 (84.727)	Loss 3.0289 (3.1017)   loss_verb 1.0680   loss_noun 1.3621	beta 0.246, 0.246, 0.164  loss_a 1.8786	gamma 0.003000  loss_e_verb 2.1089 loss_e_noun 3.2236	
Train: [20][100/126], lr: 0.00003	Time 0.095 (0.098)	Data 0.020 (0.028)	Prec@1 64.062 (64.944)	Prec@1 60.156 (63.939)	Prec@1 41.406 (45.034)	Prec@5 93.750 (95.204)	Prec@5 89.062 (88.653)	Prec@5 83.594 (85.048)	Loss 3.1573 (3.0948)   loss_verb 1.0584   loss_noun 1.3563	beta 0.250, 0.250, 0.167  loss_a 1.8795	gamma 0.003000  loss_e_verb 2.1047 loss_e_noun 3.2179	
Train: [21][0/126], lr: 0.00003	Time 0.696 (0.696)	Data 0.662 (0.662)	Prec@1 57.031 (57.031)	Prec@1 57.031 (57.031)	Prec@1 36.719 (36.719)	Prec@5 92.969 (92.969)	Prec@5 82.812 (82.812)	Prec@5 78.125 (78.125)	Loss 3.3180 (3.3180)   loss_verb 1.1987   loss_noun 1.6538	beta 0.252, 0.252, 0.168  loss_a 1.8833	gamma 0.003000  loss_e_verb 2.2247 loss_e_noun 3.3856	
Train: [21][50/126], lr: 0.00003	Time 0.089 (0.107)	Data 0.021 (0.035)	Prec@1 64.062 (64.445)	Prec@1 69.531 (63.741)	Prec@1 48.438 (44.531)	Prec@5 95.312 (95.067)	Prec@5 90.625 (88.526)	Prec@5 86.719 (84.911)	Loss 2.9902 (3.1002)   loss_verb 1.0633   loss_noun 1.3526	beta 0.257, 0.257, 0.171  loss_a 1.8842	gamma 0.003000  loss_e_verb 2.0929 loss_e_noun 3.2230	
Train: [21][100/126], lr: 0.00003	Time 0.091 (0.098)	Data 0.023 (0.028)	Prec@1 64.062 (64.627)	Prec@1 61.719 (64.813)	Prec@1 42.188 (45.351)	Prec@5 96.094 (95.042)	Prec@5 89.062 (89.055)	Prec@5 85.938 (85.427)	Loss 3.1711 (3.0831)   loss_verb 1.0597   loss_noun 1.3289	beta 0.261, 0.261, 0.174  loss_a 1.8809	gamma 0.003000  loss_e_verb 2.0900 loss_e_noun 3.2066	
Train: [22][0/126], lr: 0.00003	Time 0.742 (0.742)	Data 0.690 (0.690)	Prec@1 60.938 (60.938)	Prec@1 69.531 (69.531)	Prec@1 47.656 (47.656)	Prec@5 93.750 (93.750)	Prec@5 88.281 (88.281)	Prec@5 83.594 (83.594)	Loss 3.1308 (3.1308)   loss_verb 1.1915   loss_noun 1.2771	beta 0.263, 0.263, 0.176  loss_a 1.8888	gamma 0.003000  loss_e_verb 2.0538 loss_e_noun 3.0744	
Train: [22][50/126], lr: 0.00003	Time 0.089 (0.110)	Data 0.024 (0.034)	Prec@1 67.188 (66.268)	Prec@1 71.875 (64.185)	Prec@1 50.781 (46.094)	Prec@5 96.875 (95.190)	Prec@5 91.406 (88.848)	Prec@5 89.844 (85.493)	Loss 2.9125 (3.0804)   loss_verb 1.0359   loss_noun 1.3494	beta 0.268, 0.268, 0.178  loss_a 1.8798	gamma 0.003000  loss_e_verb 2.0842 loss_e_noun 3.1855	
Train: [22][100/126], lr: 0.00003	Time 0.081 (0.100)	Data 0.017 (0.027)	Prec@1 63.281 (65.377)	Prec@1 71.875 (64.929)	Prec@1 51.562 (45.800)	Prec@5 94.531 (95.251)	Prec@5 87.500 (89.078)	Prec@5 82.812 (85.644)	Loss 2.9907 (3.0780)   loss_verb 1.0528   loss_noun 1.3268	beta 0.272, 0.272, 0.181  loss_a 1.8803	gamma 0.003000  loss_e_verb 2.0808 loss_e_noun 3.1826	
Train: [23][0/126], lr: 0.00003	Time 0.723 (0.723)	Data 0.688 (0.688)	Prec@1 61.719 (61.719)	Prec@1 66.406 (66.406)	Prec@1 43.750 (43.750)	Prec@5 95.312 (95.312)	Prec@5 92.969 (92.969)	Prec@5 89.844 (89.844)	Loss 3.0830 (3.0830)   loss_verb 1.1778   loss_noun 1.2078	beta 0.274, 0.274, 0.183  loss_a 1.8824	gamma 0.003000  loss_e_verb 2.0426 loss_e_noun 3.1958	
Train: [23][50/126], lr: 0.00003	Time 0.085 (0.110)	Data 0.018 (0.035)	Prec@1 64.062 (64.782)	Prec@1 67.969 (64.430)	Prec@1 47.656 (44.730)	Prec@5 92.188 (95.297)	Prec@5 90.625 (88.725)	Prec@5 84.375 (85.555)	Loss 3.0949 (3.0956)   loss_verb 1.0635   loss_noun 1.3486	beta 0.278, 0.278, 0.186  loss_a 1.8817	gamma 0.003000  loss_e_verb 2.0769 loss_e_noun 3.1655	
Train: [23][100/126], lr: 0.00003	Time 0.087 (0.100)	Data 0.021 (0.028)	Prec@1 67.969 (64.681)	Prec@1 68.750 (64.712)	Prec@1 50.000 (45.111)	Prec@5 95.312 (95.343)	Prec@5 89.844 (88.970)	Prec@5 85.938 (85.698)	Loss 3.0500 (3.0871)   loss_verb 1.0580   loss_noun 1.3365	beta 0.283, 0.283, 0.189  loss_a 1.8821	gamma 0.003000  loss_e_verb 2.0728 loss_e_noun 3.1740	
Train: [24][0/126], lr: 0.00003	Time 0.727 (0.727)	Data 0.685 (0.685)	Prec@1 64.062 (64.062)	Prec@1 62.500 (62.500)	Prec@1 42.969 (42.969)	Prec@5 91.406 (91.406)	Prec@5 89.062 (89.062)	Prec@5 82.812 (82.812)	Loss 3.1099 (3.1099)   loss_verb 1.1041   loss_noun 1.3468	beta 0.285, 0.285, 0.190  loss_a 1.8765	gamma 0.003000  loss_e_verb 2.0784 loss_e_noun 3.2484	
Train: [24][50/126], lr: 0.00003	Time 0.089 (0.112)	Data 0.022 (0.033)	Prec@1 71.094 (64.721)	Prec@1 69.531 (64.874)	Prec@1 50.781 (45.542)	Prec@5 93.750 (95.021)	Prec@5 89.062 (89.354)	Prec@5 85.156 (85.922)	Loss 3.0265 (3.0788)   loss_verb 1.0687   loss_noun 1.3147	beta 0.289, 0.289, 0.193  loss_a 1.8792	gamma 0.003000  loss_e_verb 2.0708 loss_e_noun 3.1965	
Train: [24][100/126], lr: 0.00003	Time 0.080 (0.101)	Data 0.017 (0.027)	Prec@1 62.500 (65.145)	Prec@1 60.938 (64.496)	Prec@1 42.969 (45.452)	Prec@5 91.406 (95.320)	Prec@5 88.281 (88.993)	Prec@5 82.812 (85.644)	Loss 3.1944 (3.0795)   loss_verb 1.0509   loss_noun 1.3318	beta 0.293, 0.293, 0.196  loss_a 1.8802	gamma 0.003000  loss_e_verb 2.0692 loss_e_noun 3.1897	
Train: [25][0/126], lr: 0.00003	Time 0.726 (0.726)	Data 0.688 (0.688)	Prec@1 65.625 (65.625)	Prec@1 67.969 (67.969)	Prec@1 50.000 (50.000)	Prec@5 92.969 (92.969)	Prec@5 91.406 (91.406)	Prec@5 85.156 (85.156)	Loss 3.0086 (3.0086)   loss_verb 1.1634   loss_noun 1.1163	beta 0.296, 0.296, 0.197  loss_a 1.8606	gamma 0.003000  loss_e_verb 2.1718 loss_e_noun 3.2973	
Train: [25][50/126], lr: 0.00003	Time 0.080 (0.110)	Data 0.017 (0.033)	Prec@1 69.531 (65.104)	Prec@1 64.062 (64.645)	Prec@1 50.000 (45.665)	Prec@5 94.531 (95.343)	Prec@5 90.625 (89.032)	Prec@5 86.719 (85.585)	Loss 2.9859 (3.0858)   loss_verb 1.0631   loss_noun 1.3326	beta 0.300, 0.300, 0.200  loss_a 1.8801	gamma 0.003000  loss_e_verb 2.0652 loss_e_noun 3.1539	
Train: [25][100/126], lr: 0.00003	Time 0.096 (0.100)	Data 0.020 (0.026)	Prec@1 68.750 (65.161)	Prec@1 64.844 (64.790)	Prec@1 50.000 (45.506)	Prec@5 96.094 (95.196)	Prec@5 92.969 (89.225)	Prec@5 90.625 (85.644)	Loss 3.0190 (3.0833)   loss_verb 1.0576   loss_noun 1.3283	beta 0.304, 0.304, 0.203  loss_a 1.8825	gamma 0.003000  loss_e_verb 2.0714 loss_e_noun 3.1559	
Train: [26][0/126], lr: 0.00003	Time 0.727 (0.727)	Data 0.692 (0.692)	Prec@1 67.188 (67.188)	Prec@1 66.406 (66.406)	Prec@1 45.312 (45.312)	Prec@5 96.094 (96.094)	Prec@5 86.719 (86.719)	Prec@5 85.156 (85.156)	Loss 2.9778 (2.9778)   loss_verb 0.9426   loss_noun 1.2926	beta 0.306, 0.306, 0.204  loss_a 1.8524	gamma 0.003000  loss_e_verb 2.1464 loss_e_noun 3.1045	
Train: [26][50/126], lr: 0.00003	Time 0.089 (0.107)	Data 0.024 (0.035)	Prec@1 67.188 (65.319)	Prec@1 64.844 (63.710)	Prec@1 46.094 (44.991)	Prec@5 95.312 (95.420)	Prec@5 88.281 (88.680)	Prec@5 85.156 (85.279)	Loss 3.1602 (3.0963)   loss_verb 1.0606   loss_noun 1.3548	beta 0.310, 0.310, 0.207  loss_a 1.8807	gamma 0.003000  loss_e_verb 2.0599 loss_e_noun 3.1541	
Train: [26][100/126], lr: 0.00003	Time 0.093 (0.098)	Data 0.020 (0.029)	Prec@1 65.625 (65.594)	Prec@1 67.188 (64.743)	Prec@1 46.094 (45.955)	Prec@5 92.969 (95.251)	Prec@5 90.625 (89.008)	Prec@5 85.156 (85.574)	Loss 3.0754 (3.0772)   loss_verb 1.0508   loss_noun 1.3251	beta 0.314, 0.314, 0.210  loss_a 1.8815	gamma 0.003000  loss_e_verb 2.0607 loss_e_noun 3.1554	
Train: [27][0/126], lr: 0.00003	Time 0.689 (0.689)	Data 0.648 (0.648)	Prec@1 60.938 (60.938)	Prec@1 69.531 (69.531)	Prec@1 49.219 (49.219)	Prec@5 96.094 (96.094)	Prec@5 92.188 (92.188)	Prec@5 88.281 (88.281)	Loss 2.9772 (2.9772)   loss_verb 1.0168   loss_noun 1.1774	beta 0.316, 0.316, 0.211  loss_a 1.8722	gamma 0.003000  loss_e_verb 2.0621 loss_e_noun 3.1866	
Train: [27][50/126], lr: 0.00003	Time 0.092 (0.107)	Data 0.025 (0.035)	Prec@1 62.500 (64.859)	Prec@1 63.281 (64.062)	Prec@1 44.531 (44.960)	Prec@5 93.750 (94.884)	Prec@5 85.938 (89.032)	Prec@5 81.250 (85.493)	Loss 3.2115 (3.0898)   loss_verb 1.0674   loss_noun 1.3313	beta 0.320, 0.320, 0.214  loss_a 1.8826	gamma 0.003000  loss_e_verb 2.0547 loss_e_noun 3.1521	
Train: [27][100/126], lr: 0.00003	Time 0.084 (0.099)	Data 0.018 (0.028)	Prec@1 66.406 (64.913)	Prec@1 70.312 (64.666)	Prec@1 52.344 (45.459)	Prec@5 97.656 (95.127)	Prec@5 89.844 (88.877)	Prec@5 87.500 (85.497)	Loss 2.9080 (3.0847)   loss_verb 1.0598   loss_noun 1.3267	beta 0.325, 0.325, 0.216  loss_a 1.8836	gamma 0.003000  loss_e_verb 2.0633 loss_e_noun 3.1553	
Train: [28][0/126], lr: 0.00003	Time 0.662 (0.662)	Data 0.628 (0.628)	Prec@1 67.188 (67.188)	Prec@1 62.500 (62.500)	Prec@1 47.656 (47.656)	Prec@5 96.094 (96.094)	Prec@5 87.500 (87.500)	Prec@5 85.156 (85.156)	Loss 3.1939 (3.1939)   loss_verb 1.0417   loss_noun 1.5090	beta 0.327, 0.327, 0.218  loss_a 1.9111	gamma 0.003000  loss_e_verb 1.9125 loss_e_noun 3.0421	
Train: [28][50/126], lr: 0.00003	Time 0.098 (0.106)	Data 0.031 (0.035)	Prec@1 68.750 (63.511)	Prec@1 60.938 (65.181)	Prec@1 42.969 (45.129)	Prec@5 94.531 (94.930)	Prec@5 91.406 (89.292)	Prec@5 86.719 (85.723)	Loss 3.1800 (3.1011)   loss_verb 1.0875   loss_noun 1.3311	beta 0.331, 0.331, 0.220  loss_a 1.8840	gamma 0.003000  loss_e_verb 2.0649 loss_e_noun 3.1725	
Train: [28][100/126], lr: 0.00003	Time 0.092 (0.098)	Data 0.029 (0.028)	Prec@1 63.281 (64.333)	Prec@1 61.719 (65.068)	Prec@1 41.406 (45.753)	Prec@5 92.969 (95.181)	Prec@5 82.812 (89.055)	Prec@5 78.906 (85.589)	Loss 3.2350 (3.0940)   loss_verb 1.0628   loss_noun 1.3322	beta 0.335, 0.335, 0.223  loss_a 1.8887	gamma 0.003000  loss_e_verb 2.0601 loss_e_noun 3.1563	
Train: [29][0/126], lr: 0.00003	Time 0.681 (0.681)	Data 0.642 (0.642)	Prec@1 69.531 (69.531)	Prec@1 70.312 (70.312)	Prec@1 51.562 (51.562)	Prec@5 96.094 (96.094)	Prec@5 90.625 (90.625)	Prec@5 88.281 (88.281)	Loss 3.0155 (3.0155)   loss_verb 0.9262   loss_noun 1.2877	beta 0.337, 0.337, 0.224  loss_a 1.9007	gamma 0.003000  loss_e_verb 2.0386 loss_e_noun 3.2178	
Train: [29][50/126], lr: 0.00003	Time 0.090 (0.106)	Data 0.018 (0.036)	Prec@1 57.812 (64.828)	Prec@1 67.188 (65.273)	Prec@1 39.062 (46.339)	Prec@5 94.531 (95.037)	Prec@5 92.969 (88.986)	Prec@5 89.062 (85.539)	Loss 3.0745 (3.0937)   loss_verb 1.0705   loss_noun 1.3317	beta 0.341, 0.341, 0.227  loss_a 1.8848	gamma 0.003000  loss_e_verb 2.0559 loss_e_noun 3.1348	
Train: [29][100/126], lr: 0.00003	Time 0.095 (0.098)	Data 0.023 (0.028)	Prec@1 61.719 (64.898)	Prec@1 57.812 (64.186)	Prec@1 40.625 (45.189)	Prec@5 94.531 (95.297)	Prec@5 89.062 (89.086)	Prec@5 85.938 (85.682)	Loss 3.1345 (3.0881)   loss_verb 1.0579   loss_noun 1.3315	beta 0.345, 0.345, 0.230  loss_a 1.8856	gamma 0.003000  loss_e_verb 2.0556 loss_e_noun 3.1341	
Train: [30][0/126], lr: 0.00003	Time 0.714 (0.714)	Data 0.673 (0.673)	Prec@1 62.500 (62.500)	Prec@1 65.625 (65.625)	Prec@1 45.312 (45.312)	Prec@5 90.625 (90.625)	Prec@5 87.500 (87.500)	Prec@5 81.250 (81.250)	Loss 3.2765 (3.2765)   loss_verb 1.2675   loss_noun 1.4149	beta 0.347, 0.347, 0.231  loss_a 1.9275	gamma 0.003000  loss_e_verb 2.0173 loss_e_noun 3.1909	
Train: [30][50/126], lr: 0.00003	Time 0.097 (0.107)	Data 0.023 (0.035)	Prec@1 59.375 (65.824)	Prec@1 60.938 (64.874)	Prec@1 41.406 (46.094)	Prec@5 96.875 (95.267)	Prec@5 86.719 (89.262)	Prec@5 83.594 (85.815)	Loss 3.0867 (3.0564)   loss_verb 1.0383   loss_noun 1.2953	beta 0.350, 0.350, 0.234  loss_a 1.8818	gamma 0.003000  loss_e_verb 2.0566 loss_e_noun 3.1380	
Train: [30][100/126], lr: 0.00003	Time 0.094 (0.099)	Data 0.021 (0.028)	Prec@1 60.156 (65.679)	Prec@1 62.500 (65.029)	Prec@1 40.625 (46.210)	Prec@5 93.750 (95.289)	Prec@5 89.844 (89.055)	Prec@5 83.594 (85.628)	Loss 3.1854 (3.0672)   loss_verb 1.0409   loss_noun 1.3090	beta 0.354, 0.354, 0.236  loss_a 1.8844	gamma 0.003000  loss_e_verb 2.0541 loss_e_noun 3.1407	
total training time: 357.27568101882935
checkpoint
testing on the test set
preparing the model......
Multi-Scale Temporal Relation Network Module in use ['5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']
loading data......
  0%|          | 0/16 [00:00<?, ?it/s]/home/ac1xliu/experiments/DAAR/epicuda/EPIC-KITCHENS-100_UDA_TA3N/models.py:477: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  base_out = (self.softmax(base_out[0]), self.softmax(base_out[1]))
Testing Results: Prec@1 verb 32.368  Prec@1 noun 21.579 Prec@1 action 11.384 Prec@5 verb 72.894 Prec@5 noun 44.397 Prec@5 action 37.288 Loss 4.94367
